---
title: "Pandas 개념정리"
date : "2025-03-10"
author: "Jiwon Shin"
categories: [news, code, analysis]
image: "Pandas-logo.webp"
---

## 판다스 활용하기

### 데이터 프레임(Data Frame)이란?
각 열에 있는 데이터 타입이 달라도 괜찮다!  
```{python}
import pandas as pd

# 데이터 프레임 생성
df = pd.DataFrame({
    'col-str': ['one', 'two', 'three', 'four','five'],
    'col-num': [6, 7, 8, 9, 10]
})
df
print(df)

print(df['col-str'].dtype)  # object
print(df['col-num'].dtype)  # integer

```

### 시리즈(series)란 무엇일까?
1차원 구조를 지님.  
그렇기 때문에 하나의 데이터 타입을 가지고 있다!
```{python}
data = [10, 20, 30]
df_s = pd.Series(data, index=['one', 'two', 'three'])
print(df_s)
df_s.shape

# 시리즈는 columns을 통해 열 이름을 확인할 수 없음
# df_s.columns 

# name을 통해 시리즈 이름을 확인할 수 있음
df_s.name
```

#### 데이터 프레임 채우면서 만들기
```{python}
my_df = pd.DataFrame({
    'name': ['issac', 'bomi'],
    'birthmonth': [5, 4]
})
print(my_df)
```

```{python}
df = pd.DataFrame({
    'studnet_id': [1,2,3],
    'gender': ['F', 'M', 'F'],
    'midterm': [38,42,53]
}, index = ["first", "second", "third"])
print(df)

df['gender'] # gender 행 전체를 가져옴.
```

```{python}
my_s = pd.Series(['F', 'M', 'F'],
                  name = "gender", index = ["first", "second", "third"])
my_s
pd.DataFrame(my_s)
```

#### csv 파일로 읽어오기
```{python}
url = "https://bit.ly/examscore-csv"
mydata = pd.read_csv(url)
mydata.head(10) # 위에서 10개의 열만 가져옴

mydata['gender'].head()
mydata[['gender','student_id']].head()
```

```{python}
import numpy as np 
# mydata
# mydata[mydata['gender'] == "F", :]  # 에러발생
mydata.loc[mydata['gender'] == "F", :]  #작동
mydata[mydata['gender'] == "F"]   #작동
check_f = np.array(mydata['gender'] == "F") # 작동
mydata.iloc[check_f, :]

mydata[mydata['midterm'] <= 15]
```

```{python}
# 중간고사 점수 45 - 60점 사이 학생은 몇명인가요?
check_score = (mydata['midterm'] >= 45) & (mydata['midterm'] <= 60)
mydata[check_score].shape[0]
```


### 데이터 프레임 인덱싱
데이터 프레임 내의 특정 데이터를 효율적으로 필터링 및 조작할 수 있다.  

#### iloc[]를 이용한 필터링
```{python}
# 대괄호 안에 숫자를 써서 인덱스 불가
# .iloc 함수를 사용하면 가능!
# mydata[1:4,0]  불가능!
mydata.iloc[0, 0] # 1행 1열에 있는 숫자 -> 1!
mydata.iloc[1:4,1:3]
```

```{python}
# .iloc 함수는 인덱스가 문자여도 잘 작동
mydata2 = mydata.iloc[:4,:3]
mydata2.index
mydata2.index = ["first", "second", "third", "fourth"]
mydata2
mydata2.iloc[0:2,0]

# .iloc 함수는 : 도 잘 작동함!
mydata2.iloc[:,0]
```

리스트 형태로 필터링할 경우 DataFrame으로 변경됨
```{python}
# .iloc 함수는 결과값의 타입이 변동함.
mydata2.iloc[0, 1] # 결과 : 값 하나
mydata2.iloc[0:2, 1] # 결과 : 시리즈
mydata2.iloc[2, 0:2] # 결과 : 시리즈
mydata2.iloc[0:3, 0:2]  #결과 :데이터프레임
result1 = mydata2.iloc[:,0] # 결과 : 시리즈
result2 = mydata2.iloc[:, [0]] # 결과 : 데이터프레임
result1[1]                           
result2.iloc[1,0]

# DataFrame을 Series로 변경하기 위해서 squeeze()활용!
mydata2.iloc[:, [0]].squeeze() # 결과: 시리즈
```

#### loc()를 이용한 필터링
```{python}
# 라벨을 이용한 인덱싱 loc[] - p20
mydata.loc[mydata['midterm'] <= 15]
mydata.loc[mydata['midterm'] <= 15, "student_id"]
mydata.loc[mydata['midterm'] <= 15, ["student_id"]]
mydata.loc[mydata['midterm'] <= 15, ["student_id", "gender"]]

mydata['midterm'].iloc[0] # 0번째 값이 무엇이 들어있는지 확인
```

#### isin[] 활용하기
특정 값이 데이터 프레임 내에 존재하는지 확인하고,  
조건을 만족하는 행을 필터링하는데 사용
```{python}
# 28,38,52 중 값이 있는지 TRUE,FALSE 값을 반환
mydata['midterm'].isin([28, 38, 52]) 
# ~를 붙이면 특정값을 제외함(앞줄이랑 반대)
~mydata['midterm'].isin([28, 38, 52]) 
mydata.loc[mydata['midterm'].isin([28, 38, 52])]
mydata.loc[~mydata['midterm'].isin([28, 38, 52])]
```

### 완전한 표본 체크하기
```{python}
# 데이터에 빈칸이 뜷려있는 경우
mydata.iloc[3, 2] = np.nan
mydata.iloc[10, 3] = np.nan
mydata.iloc[13, 1] = np.nan

mydata["gender"].isna()

mydata.loc[mydata["gender"].isna()]
mydata.loc[~mydata["gender"].isna()]

mydata.dropna()
```

```{python}
# Q. mydata에서 중간고사와 기말고사가 
# 다 채워진 행들을 가져오세요.

con1 = ~mydata["midterm"].isna() # 중간고사 채워진 애들
con2 = ~mydata["final"].isna() # 기말고사 채워진 애들

```

### 구성원소 추가/삭제/변경
```{python}
# mydata에 final 열을 추가가
mydata['total'] = mydata['midterm'] + mydata['final']
mydata

mydata["midterm"].isna()
# midterm 열에 빈칸을 50으로 채워줌
mydata["midterm"].loc[mydata["midterm"].isna()] = 50 

mydata["midterm"].isna().sum() # 빈칸이 몇개 있는지 체크!
mydata["final"].isna().sum() # 빈칸이 몇개 있는지 체크!
# final 열에 빈칸을 30으로 채워줌. 
mydata["final"].loc[mydata["final"].isna()] = 30
```

#### 변경 및 추가 
```{python}
(mydata['total'] / 2).rename('average')
mydata = pd.concat([mydata, (mydata['total'] /2).rename('average')], axis = 1)

# 열 삭제
del mydata["gender"]

mydata.columns

```

#### pd.concat() 함수
프레임이나 시리즈를 연결하는데 사용
```{python}
#  에제1 : 두개 데이터 프레임 연결하기(axis=0-행방향)
import pandas as pd
df1 = pd.DataFrame({
'A': ['A0', 'A1', 'A2'],
'B': ['B0', 'B1', 'B2']
})
df2 = pd.DataFrame({
'A': ['A3', 'A4', 'A5'],
'B': ['B3', 'B4', 'B5']
})
result = pd.concat([df1, df2])
```


```{python}
#  에제2 : 열방향으로 연결
df3 = pd.DataFrame({
'C': ['C0', 'C1', 'C2'],
'D': ['D0', 'D1', 'D2']
})

# axis = 1 옵션으로 인해 열 방향으로 합쳐졌다.
result = pd.concat([df1, df3], axis=1)
```


```{python}
# 에제3 : ignore_index 옵션 사용

# ignore_index = True 옵션으로 인해 행 번호 중복 출력 x
pd.concat([df1, df2], ignore_index = True)
```

```{python}
# 예제4: join 옵션 사용
df4 = pd.DataFrame({
'A': ['A2', 'A3', 'A4'],
'B': ['B2', 'B3', 'B4'],
'C': ['C2', 'C3', 'C4']
})

# join = 'inner' 는 공통 열만 포함하는 결합
result = pd.concat([df1, df4], join='inner')

# join = 'outer'는 모든 열을 포함하는 외부 결합;
# 하나의 데이터 프레임에만 존재하는 열은 NaN
result = pd.concat([df1, df4], join='outer')
```

```{python}
# 예제 5: keys 옵션 사용

# keys 옵션 사용시 연결된 데이터 프레임의 원본 출처를 
# 식별하는 멀티인덱스 생성
df_wkey = pd.concat([df1, df2], keys=['key1', 'key2'])
df_wkey.loc['key2']
```

### 판다스 데이터 프레임에서 이용가능한 메서드
head() - 데이터 프레임의 처음 몇개 행을 반환  
```{python}
import pandas as pd
from palmerpenguins import load_penguins
df = load_penguins()
df.head()
```

tail() - 데이터 프레임의 마지막 몇개의 행을 반환  
```{python}
df.tail()
```

describe() - 데이터 프레임의 요약 통계를 반환
```{python}
df.describe()
```

info() - 데이터 프레임의 정보(컬럼,타입 등)
```{python}
df.info()
```

sort_values() - 특정 열을 기준으로 데이터 프레임 정렬
```{python}
# 내림차순 정렬: ascending =False
# 'bill_length_mm' 열을 기준으로 데이터 프레임 정렬 - 오름차순
sorted_df = df.sort_values(by='bill_length_mm', ascending=False)
sorted_df.head()

# 'bill_length_mm'를 내림차순으로, 'bill_depth_mm'를 오름차순으로 정렬
sorted_df = df.sort_values(
by=['bill_length_mm', 'bill_depth_mm'],
ascending=[False, True]
)
sorted_df.head()
```

idmax() & idxmin() - 각 데이터프레임이나 시리즈에서 최대값.최소값을 가지는 첫 인덱스 반환
```{python}
# 'bill_length_mm' 열에서 최대값을 가지는 행의 인덱스 반환
max_idx = df['bill_length_mm'].idxmax()
max_idx

# loc 매서드는 해당 인덱스에 위치한 행의 데이터를 출력
df.loc[max_idx]
```

```{python}
# 'bill_length_mm' 열에서 최소값을 가지는 행의 인덱스 반환
min_idx = df['bill_length_mm'].idxmin()
min_idx

# loc 매서드는 해당 인덱스에 위치한 행의 데이터를 출력
df.loc[min_idx]
```


groupby() - 특정 열을 기준으로 데이터 프레임 그룹화
```{python}
# 'species' 열을 기준으로 그룹화하여 평균 계산
grouped_df = df.groupby('species').mean(numeric_only = True)
grouped_df

```

mean() - 데이터 프레임의 평균 계산
```{python}
# 데이터 프레임의 각 열의 평균 계산
print(df.mean(numeric_only = True))
```

```{python}
# 'species' 열을 기준으로 그룹화하여 평균 계산
grouped_df = df.groupby('species').mean(numeric_only = True)
print(grouped_df)

df.groupby('island').mean(numeric_only=True)
```

sum() - 데이터 프레임의 합계 계산
```{python}
# 데이터 프레임의 각 열의 합계 계산
print(df.sum(numeric_only = True))
```

```{python}
# 최대 부리길이 60인 펭귄은 몇마리?
sum(df['bill_length_mm'] == 60.0)
```


### 연습문제
연습1
```{python}
midterm= pd.DataFrame({'id' : [23, 10, 5, 1], 'midterm':[40, 30, 50,20]})
final = pd.DataFrame({'id' : [23, 10, 5, 1], 'final':[45, 25, 50, 17]})

pd.merge(midterm, final, on = 'id', how = 'outer')
```

연습2

* 1 성별, 섬별 부리길이 평균계산
```{python}
bill_length = df.groupby(["sex","island"], as_index = False)['bill_length_mm'].mean(numeric_only=True)
```

* 2. 성별, 섬별 부리깊이 평균계산
```{python}
bill_depth = df.groupby(['sex','island'], as_index = False)['bill_depth_mm'].mean(numeric_only=True)
```

* 3. 1.2 단계 데이터 프레임 병합해서 성별, 섬별, 부리길이,깊이 데이터 프레임 만들기
```{python}
merged_df = pd.merge(bill_length, bill_depth, on=["sex","island"],how ='outer')
# 오류 발생??
# loc는 행 인덱스를 기준으로 접근하는 방법
# merged_df.loc["female"]
merged_df[merged_df['sex'] == 'female']

```

merge() - 두 데이터 프레임 병합
```{python}
# 예제 데이터 프레임 생성
df1 = pd.DataFrame({'key': ['A', 'B', 'C'], 'value': [1, 2, 3]})
df2 = pd.DataFrame({'key': ['A', 'B', 'D'], 'value': [4, 5, 6]})

# 두 데이터 프레임 병합
# on = 'key' 병합할때 기준이 되는 열 지정
# how = 'inner'병합 방법지정; inner(교집합), outer(합집합)
merged_df = pd.merge(df1, df2, on='key', how='inner') 
print(merged_df)

# 두 데이터 프레임을 outer join으로 병합
merged_df_outer = pd.merge(df1, df2, on='key', how='outer')
print(merged_df_outer)
```


### 데이터 재구조화 - p69
#### melt() 메서드
데이터를 넓은 형식에서 긴형식으로 변환
```{python}
data = {
    'Date': ['2024-07-01', '2024-07-02', '2024-07-03'],
    'Temperature': [10, 20, 25],
    'Humidity': [60, 65, 70]
}

df = pd.DataFrame(data)

df_melted = pd.melt(df,
    id_vars=['Date'],
    value_vars=['Temperature', 'Humidity'],
    var_name='Variable',
    value_name='Value'
    )

df_melted
```

```{python}
# 또 다른 예제
data = {
    'Country': ['Afghanistan', 'Brazil', 'China'],
    '2024년': [745, 37737, 212258],
    '2025년': [2666, 80488, 213766]
}

df_wide = pd.DataFrame(data)
df_wide

df_long = pd.melt(df_wide,
    id_vars = ['Country'],
    value_vars = ['2024년','2025년'],
    var_name= 'Year',
    value_name= 'cases'
    )
```

#### pivot() 메서드 
데이터를 긴형식에서 넓은 형식으로 변환
```{python}
df_pivoted = df_melted.pivot(
    index='Date',
    columns='Variable',
    values='Value').reset_index()
df_pivoted

```

```{python}
# 연습데이터
data = {
    'Country': ['Afghanistan', 'Brazil', 'China'],
    '2024년': [745, 37737, 212258],
    '2025년': [2666, 80488, 213766]
}

df_wide = pd.DataFrame(data)
df_wide

df_long = pd.melt(df_wide,
    id_vars = ['Country'],
    value_vars = ['2024년','2025년'],
    var_name= 'Year',
    value_name= 'cases'
    )

# pivot 사용해서 wide 형식으로 바꾸려면?
df_wide2 = df_long.pivot(
    index='Country',
    columns='Year',
    values='cases').reset_index()

df_wide2.shape

df_wide2.iloc[0,0]
df_wide2.columns.name = None  # 불필요한 인덱스 이름제거
df_wide2
```

깔끔한 데이터 조건  
1. 각 칼럼이 하나의 변수를 의미한다.  
2. 각 행이 하나의 관측치를 나타낸다.  
3. 각 칸에 하나의 값이 들어있다. 

```{python}
df = pd.DataFrame({
    'School' : ['A','A', 'B', 'B','C', 'C'],
    'Gender' : ["M", 'F', "M", 'F', 'M', 'F'],
    'City' : ['North', 'South', 'North', 'South', 'North', 'South'],
    'Midterm' : [ 10, 20, 30, 40, 50, 60],
    'Final' : [5, 15, 25, 35, 45, 55]
})

df
```


```{python}
# 학교별 중간고사 평균
df.pivot_table(
    index='School',
    values=['Midterm', 'Final'],
    aggfunc = 'mean').reset_index()

# 학교별 중간고사,기말고사 평균
df.pivot_table(
    index='School',
    columns='City',
    values=['Midterm', 'Final'],
    aggfunc = 'mean').reset_index()
```

```{python}
# column 옵션에 의미
df.pivot_table(
    index='School',
    columns='City',
    values=['Midterm', 'Final'],
    aggfunc = 'mean').reset_index()

# 인덱스가 여러개
df.pivot_table(
    index=['School', 'Gender'],
    values='Midterm',
    aggfunc = 'mean').reset_index()
```

```{python}
# aggfunc의 사용
# 나만의 함수 
# 벡터 원소들을 더 한 수의 제곱을 하는 함수 my_f

def my_f(input):
    return sum(input)**2

df.pivot_table(
    index='School',
    values='Midterm',
    aggfunc = my_f).reset_index()
```


### 실습 팔머펭귄 데이터 분석 - Pivot table
```{python}
import pandas as pd
from palmerpenguins import load_penguins
penguins = load_penguins()
```

문제1. 펭귄 종별 평균 부리 길이 구하기
```{python}
penguins.pivot_table(
    index='species',
    values= 'bill_length_mm',
    aggfunc = 'mean').reset_index()
```

문제2: 섬별 몸무게 중앙값 구하기
```{python}
penguins.pivot_table(
    index='island',
    values= 'body_mass_g',
    aggfunc = 'median').reset_index()
```

문제3: 성별에 따른 부리길이와 몸무게 평균 구하기
```{python}
penguins.pivot_table(
    index=['sex','species'],
    values= ['bill_length_mm','body_mass_g'],
    aggfunc = 'mean').reset_index()
```

문제4: 종과 섬에 따른 평균 지느러미 길이 구하기
```{python}
penguins.pivot_table(
    index=['species','island'],
    values= ['flipper_length_mm'],
    aggfunc = 'mean').reset_index()
```

문제 5: 종과 성별에 따른 부리 깊이 합계 구하기
```{python}
penguins.pivot_table(
    index=['species','sex'],
    values= 'bill_depth_mm',
    aggfunc = 'sum').reset_index()
```

문제6: 종별 몸무게의 변동 범위 구하기
```{python}
def my_f(input):
    return input.max() - input.min()

penguins.pivot_table(
    index='species',
    values= 'body_mass_g',
    aggfunc = my_f).reset_index()
```

### 학생 성적 불러오기
```{python}
df = df = pd.read_csv('c:\\Users\\USER\\Documents\\lsbigdata-gen4\\data\\dat.csv')

df.head()
df.info()

set(df["grade"])

# 여러 칼럼 선택
df.loc[:, ['school', 'sex', 'paid', 'goout']]
```


### 칼럼 데이터 타입 변경
최빈값으로 대체?
기존 데이터 형태의 정수값으로 대체 가능(장점)
전체 변수의 평균값이 변경 될 수 있음(단점)

평균값으로 대체?
전체 변수의 평균값이 그대로 유지(장점)
데이터 극단값이 존재할 경우 영향을 받을 가능성(단점)
평균값 소수점으로 나올 수 있음(단점)


#### 여러 메서드
rename() 메서드 
특정 칼럼 이름 변경
```{python}
df.rename(columns = {'Dalc' : 'dalc', 'Walc' : 'walc'})
```

astype() 메서드
데이터 프레임 또는 시리즈의 데이터 타입을 변경하는데 사용
```{python}
# 최빈값 대체코드
mode_val = df.loc[:, ['goout']].mode()
df['goout'].isna()

df.loc[df['goout'].isna(), "goout"] = 3.0
df["goout"] = df.loc[:, ['goout']].astype({'goout' : 'int64'})
df
```

assign() 메서드
새로운 칼럼을 생성하거나 특정 칼러 값을 변경 하는데 사용
```{python}
def classify_famrel(famrel):
     if famrel <= 2:
        return 'Low'
     elif famrel <= 4:
         return 'Medium'
     else:
         return 'High'

# famrel_quality 칼럼 생성       
df = df.assign(famrel_quality=df['famrel'].apply(classify_famrel))
df
```

select_dtypes() 메서드
데이터프레임에서 특정 데이터 타입을 가진 칼럼만 선택하는데 사용되는 메서드
```{python}
df.select_dtypes('number')
df.select_dtypes('object')


def standardize(x):
     return (x - np.nanmean(x)/np.std(x))

df.select_dtypes('number').apply(standardize, axis = 0)
```