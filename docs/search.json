[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "jiwon-blog",
    "section": "",
    "text": "Pandas 연습문제제\n\n\n\n\n\n\nQuestion\n\n\ncode\n\n\n\n\n\n\n\n\n\nMar 13, 2025\n\n\nJiwon Shin\n\n\n\n\n\n\n\n\n\n\n\n\nPandas string 개념정리\n\n\n\n\n\n\nnews\n\n\ncode\n\n\n\n\n\n\n\n\n\nMar 11, 2025\n\n\nJiwon Shin\n\n\n\n\n\n\n\n\n\n\n\n\nPandas 개념정리\n\n\n\n\n\n\nnews\n\n\ncode\n\n\n\n\n\n\n\n\n\nMar 10, 2025\n\n\nJiwon Shin\n\n\n\n\n\n\n\n\n\n\n\n\n나의 첫 블로그 포스트\n\n\n\n\n\n\npython\n\n\npandas\n\n\nnumpy\n\n\n\n\n\n\n\n\n\nMar 7, 2025\n\n\nJiwon Shin\n\n\n\n\n\n\n\n\n\n\n\n\nNumPy 개념정리\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nMar 7, 2025\n\n\nJiwon Shin\n\n\n\n\n\n\n\n\n\n\n\n\nPalmer Penguin Analysis\n\n\n\n\n\n\nnews\n\n\ncode\n\n\n\n\n\n\n\n\n\nMar 7, 2025\n\n\nJiwon Shin\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nMar 6, 2025\n\n\nHarlow Malloc\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nMar 3, 2025\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "import numpy as np\n\na = np.arange(10)\na\n\narray([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n\nThis is a post with executable code."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Jiwon",
    "section": "",
    "text": "통계와 데이터 분석 공부 중 ::smile::"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/palmer_penguin_analysis/index.html",
    "href": "posts/palmer_penguin_analysis/index.html",
    "title": "Palmer Penguin Analysis",
    "section": "",
    "text": "Palmer Penguin 종별 분석"
  },
  {
    "objectID": "posts/palmer_penguin_analysis/index.html#문제-각-펭귄-종별-특징-알아내기.",
    "href": "posts/palmer_penguin_analysis/index.html#문제-각-펭귄-종별-특징-알아내기.",
    "title": "Palmer Penguin Analysis",
    "section": "문제 : 각 펭귄 종별 특징 알아내기.",
    "text": "문제 : 각 펭귄 종별 특징 알아내기.\n\n데이터 불러오기\n\n\nimport pandas as pd\nfrom palmerpenguins import load_penguins\npenguins = load_penguins()\npenguins.info()\ndf=penguins # 편의상 df 변수 사용.\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 344 entries, 0 to 343\nData columns (total 8 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   species            344 non-null    object \n 1   island             344 non-null    object \n 2   bill_length_mm     342 non-null    float64\n 3   bill_depth_mm      342 non-null    float64\n 4   flipper_length_mm  342 non-null    float64\n 5   body_mass_g        342 non-null    float64\n 6   sex                333 non-null    object \n 7   year               344 non-null    int64  \ndtypes: float64(4), int64(1), object(3)\nmemory usage: 21.6+ KB\n\n\n\n데이터 분석을 위해 df 에 어떤 데이터가 있는지 확인한다.\n\n\ndf\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n339\nChinstrap\nDream\n55.8\n19.8\n207.0\n4000.0\nmale\n2009\n\n\n340\nChinstrap\nDream\n43.5\n18.1\n202.0\n3400.0\nfemale\n2009\n\n\n341\nChinstrap\nDream\n49.6\n18.2\n193.0\n3775.0\nmale\n2009\n\n\n342\nChinstrap\nDream\n50.8\n19.0\n210.0\n4100.0\nmale\n2009\n\n\n343\nChinstrap\nDream\n50.2\n18.7\n198.0\n3775.0\nfemale\n2009\n\n\n\n\n344 rows × 8 columns\n\n\n\n\n종과 colomm에 따른 데이터 분류\n\n\n각 종별 서식지 분포\n각 종별 테어난 연도 분포\n각 종별 부리의 길이\n각 종별 성별\n각 종별 지느러미\n각 종별 무게\n\n담당 자: 신태선\n\n종의 종류와 개수를 파악한다.\n\n\n# 종의 종류\nunique_species = df['species'].unique()\nprint(f\"Species의 종류: {unique_species}\")\n# 종의 개수 \nnum_species = df['species'].nunique()\nprint(f\"Species의 종류 개수: {num_species}\")\n\nSpecies의 종류: ['Adelie' 'Gentoo' 'Chinstrap']\nSpecies의 종류 개수: 3\n\n\n\n총 3개의 종의 Data Fram을 나누어 저장한다.\n\n\nadelie = df[df['species']== 'Adelie']\nchinstrap = df[df['species']== 'Chinstrap']\ngentoo = df[df['species']== 'Gentoo']\n\n\n각 종별 서식지 분포\n\n\nadelie_island_counts = adelie['island'].value_counts()\nadelie_island_counts.name = 'Adelie_island'\n\nchinstrap_island_counts = chinstrap['island'].value_counts()\nchinstrap_island_counts.name = 'Chinstrap_island'\n\ngentoo_island_counts = gentoo['island'].value_counts()\ngentoo_island_counts.name = 'Gentoo_island'\n\n# 병합\npenguins_island_df = pd.concat([adelie_island_counts, chinstrap_island_counts, gentoo_island_counts], axis=1).fillna(0)\npenguins_island_df\n\n\n\n\n\n\n\n\nAdelie_island\nChinstrap_island\nGentoo_island\n\n\nisland\n\n\n\n\n\n\n\nDream\n56\n68.0\n0.0\n\n\nTorgersen\n52\n0.0\n0.0\n\n\nBiscoe\n44\n0.0\n124.0\n\n\n\n\n\n\n\n\nAdelie는 152마리 중 Dream에 56 마리, Torgersen에 52마리, Biscoe에 44마리 서식중이다.\nChinstrap은 68마리 중 Dream에서만 68마리 서식중이다.\nGentoo는 124마리 중 Biscoe 지역에서만 124마리 서식중이다.\n\n\n추론\nAdelie 펭귄은 가장 넓은 환경에서 생존이 가능하므로, 다양한 환경 변화에도 적응할 가능성이 높다.\n\n\n각 종별 태어난 연도 분포\n\n\nadelie_year_counts = adelie['year'].value_counts()\nadelie_year_counts.name = 'Adelie_year'\n\ngentoo_year_counts = gentoo['year'].value_counts()\ngentoo_year_counts.name = 'Gentoo_year'\n\nchinstrap_year_counts = chinstrap['year'].value_counts()\nchinstrap_year_counts.name = 'Chinstrap_year'\n\npenguins_year_df = pd.concat([adelie_year_counts, gentoo_year_counts, chinstrap_year_counts], axis=1)\npenguins_year_df\n\n\n\n\n\n\n\n\nAdelie_year\nGentoo_year\nChinstrap_year\n\n\nyear\n\n\n\n\n\n\n\n2009\n52\n44\n24\n\n\n2007\n50\n34\n26\n\n\n2008\n50\n46\n18\n\n\n\n\n\n\n\n\n추론\n2007~2009년 사이에\nAdelie는 출생 개체 수가 비슷하다. 환경적 요인의 변화가 적었던것 같다.\nGentoo는 2007년 출생 개체 수가 가장 낮고, 다른 년도와 비교했을때 차이가 10이상으로 크다. 2007년 출생을 결정하는 환경적 요인 변화가 컸을 가능성이 있다.\nChinstrap은 2008년 출생 개체 수가 가장 낮고, 다른 년도와 비교했을 때 차이가 크다. 2008년 출생을 결정하는 환경적인 요인 변화가 컸을 가능성이 있다."
  },
  {
    "objectID": "posts/palmer_penguin_analysis/index.html#각-종별-부리의-길이",
    "href": "posts/palmer_penguin_analysis/index.html#각-종별-부리의-길이",
    "title": "Palmer Penguin Analysis",
    "section": "각 종별 부리의 길이",
    "text": "각 종별 부리의 길이"
  },
  {
    "objectID": "posts/palmer_penguin_analysis/index.html#각-종별-성별",
    "href": "posts/palmer_penguin_analysis/index.html#각-종별-성별",
    "title": "Palmer Penguin Analysis",
    "section": "각 종별 성별",
    "text": "각 종별 성별"
  },
  {
    "objectID": "posts/palmer_penguin_analysis/index.html#bill-length-부리의길이-bill-depth-부리-깊이",
    "href": "posts/palmer_penguin_analysis/index.html#bill-length-부리의길이-bill-depth-부리-깊이",
    "title": "Palmer Penguin Analysis",
    "section": "bill length = 부리의길이 bill depth = 부리 깊이",
    "text": "bill length = 부리의길이 bill depth = 부리 깊이"
  },
  {
    "objectID": "posts/palmer_penguin_analysis/index.html#펭귄-성별에-따라-개체수-구하기",
    "href": "posts/palmer_penguin_analysis/index.html#펭귄-성별에-따라-개체수-구하기",
    "title": "Palmer Penguin Analysis",
    "section": "펭귄 성별에 따라 개체수 구하기",
    "text": "펭귄 성별에 따라 개체수 구하기\n\nnan_penguins = penguins['sex'].isna().sum()\nfemale_adelie = penguins.loc[(penguins['species'] == 'Adelie') & (penguins['sex']==\"female\")].shape[0]\nmale_adelie = penguins.loc[(penguins['species'] == 'Adelie') & (penguins['sex']==\"male\")].shape[0]\nfemale_gentoo = penguins.loc[(penguins['species'] == 'Gentoo') & (penguins['sex']==\"female\")].shape[0]\nmale_gentoo = penguins.loc[(penguins['species'] == 'Gentoo') & (penguins['sex']==\"male\")].shape[0]\nfemale_chinstrap = penguins.loc[(penguins['species'] == 'Chinstrap') & (penguins['sex']==\"female\")].shape[0]\nmale_chinstrap = penguins.loc[(penguins['species'] == 'Chinstrap') & (penguins['sex']==\"male\")].shape[0]"
  },
  {
    "objectID": "posts/palmer_penguin_analysis/index.html#개체수-print함수-이용하여-정리하기",
    "href": "posts/palmer_penguin_analysis/index.html#개체수-print함수-이용하여-정리하기",
    "title": "Palmer Penguin Analysis",
    "section": "개체수 print함수 이용하여 정리하기",
    "text": "개체수 print함수 이용하여 정리하기\n\n#각 종의 암컷, 수컷의 개체수\nprint(\"Adelie 암컷의 수 : \",female_adelie,'Adelie 수컷의 수 : ',male_adelie, 'Gentoo 암컷의 수 : ',female_gentoo,\n      'Gentoo 수컷의 수 : ', male_gentoo, 'Chinstrap 암컷의 수 :', female_chinstrap, 'Chinstrap 수컷의 수 : ' ,male_chinstrap\n      ,'구별불가 펭귄의 수 : ', nan_penguins)\n\nAdelie 암컷의 수 :  73 Adelie 수컷의 수 :  73 Gentoo 암컷의 수 :  58 Gentoo 수컷의 수 :  61 Chinstrap 암컷의 수 : 34 Chinstrap 수컷의 수 :  34 구별불가 펭귄의 수 :  11\n\n\n\n결론 : Adelie, gentoo, chinstrap순으로 펭귄 숫자가 많았고 모든펭귄에서 동등한 성비를 가졌다."
  },
  {
    "objectID": "posts/palmer_penguin_analysis/index.html#종별-부리-깊이-구분짓기",
    "href": "posts/palmer_penguin_analysis/index.html#종별-부리-깊이-구분짓기",
    "title": "Palmer Penguin Analysis",
    "section": "종별 부리 깊이 구분짓기",
    "text": "종별 부리 깊이 구분짓기\n\n#종별 구분짓기 A는 아델리\nadelie = penguins.loc[(penguins['species'] == 'Adelie'),['bill_depth_mm']]\ngentoo = penguins.loc[(penguins['species'] == 'Gentoo'),['bill_depth_mm']]\nchinstrap = penguins.loc[(penguins['species'] == 'Chinstrap'),['bill_depth_mm']]\nadelie_d =  adelie.describe()\ngentoo_d = gentoo.describe()\nchinstrap_d = chinstrap.describe()"
  },
  {
    "objectID": "posts/palmer_penguin_analysis/index.html#describe이용하여-부리깊이-구하기",
    "href": "posts/palmer_penguin_analysis/index.html#describe이용하여-부리깊이-구하기",
    "title": "Palmer Penguin Analysis",
    "section": ".describe()이용하여 부리깊이 구하기",
    "text": ".describe()이용하여 부리깊이 구하기\n\nadelie_d.index = ['표본개수', '평균','표준편차','최솟값','25%','50%','75%','최대값']\ngentoo_d.index = ['표본개수', '평균','표준편차','최솟값','25%','50%','75%','최대값']\nchinstrap_d.index = ['표본개수', '평균','표준편차','최솟값','25%','50%','75%','최대값']\n\n\nadelie_d.rename(columns={'bill_depth_mm': '부리깊이'})\n\n\n\n\n\n\n\n\n부리깊이\n\n\n\n\n표본개수\n151.000000\n\n\n평균\n18.346358\n\n\n표준편차\n1.216650\n\n\n최솟값\n15.500000\n\n\n25%\n17.500000\n\n\n50%\n18.400000\n\n\n75%\n19.000000\n\n\n최대값\n21.500000\n\n\n\n\n\n\n\n\ngentoo_d.rename(columns={'bill_depth_mm': '부리깊이'})\n\n\n\n\n\n\n\n\n부리깊이\n\n\n\n\n표본개수\n123.000000\n\n\n평균\n14.982114\n\n\n표준편차\n0.981220\n\n\n최솟값\n13.100000\n\n\n25%\n14.200000\n\n\n50%\n15.000000\n\n\n75%\n15.700000\n\n\n최대값\n17.300000\n\n\n\n\n\n\n\n\nchinstrap_d.rename(columns={'bill_depth_mm': '부리깊이'})\n\n\n\n\n\n\n\n\n부리깊이\n\n\n\n\n표본개수\n68.000000\n\n\n평균\n18.420588\n\n\n표준편차\n1.135395\n\n\n최솟값\n16.400000\n\n\n25%\n17.500000\n\n\n50%\n18.450000\n\n\n75%\n19.400000\n\n\n최대값\n20.800000\n\n\n\n\n\n\n\n\n결론 : chinstrap 펭귄이 평균 18.42mm으로 가장 깊은 부리를 가졌고 gentoo 펭귄이 14.98mm로 가장 얕은 부리를 가졌다"
  },
  {
    "objectID": "posts/palmer_penguin_analysis/index.html#각-종별-지느러미-분석",
    "href": "posts/palmer_penguin_analysis/index.html#각-종별-지느러미-분석",
    "title": "Palmer Penguin Analysis",
    "section": "각 종별 지느러미 분석",
    "text": "각 종별 지느러미 분석\n\n# flipper_length_mm\n\n# 'flipper_length_mm' 컬럼에 대한 describe() 결과\ng_flipper_desc = gentoo['flipper_length_mm'].describe()\na_flipper_desc = adelie['flipper_length_mm'].describe()\nc_flipper_desc = chinstrap['flipper_length_mm'].describe()\n\n# 평균, 최대값, 최소값 추출\nmean_val = g_flipper_desc['mean']\nmax_val = g_flipper_desc['max']\nmin_val = g_flipper_desc['min']\n\nmean_val_a = a_flipper_desc['mean']\nmax_val_a = a_flipper_desc['max']\nmin_val_a = a_flipper_desc['min']\n\nmean_val_c = c_flipper_desc['mean']\nmax_val_c = c_flipper_desc['max']\nmin_val_c = c_flipper_desc['min']\n\n# gentoo\nprint(f\"Gentoo의 flipper_length의 평균: {mean_val}, 최대값: {max_val}, 최소값: {min_val}\")\n\n# adelie\nprint(f\"Adelie의 flipper_length의 평균: {mean_val_a}, 최대값: {max_val_a}, 최소값: {min_val_a}\")\n\n# chinstrap\nprint(f\"Chinstrap의 flipper_length의 평균: {mean_val_c}, 최대값: {max_val_c}, 최소값: {min_val_c}\")\n\nGentoo의 flipper_length의 평균: 217.1869918699187, 최대값: 231.0, 최소값: 203.0\nAdelie의 flipper_length의 평균: 189.95364238410596, 최대값: 210.0, 최소값: 172.0\nChinstrap의 flipper_length의 평균: 195.8235294117647, 최대값: 212.0, 최소값: 178.0\n\n\n\n\n\n\nGentoo\nAdelie\nChinstrap\n\n\n\n\n평균 지느러미 길이\n217.187\n189.954\n195.824\n\n\n최대 지느러미 길이\n231\n210\n212\n\n\n최소 지느러미 길이\n203\n172\n178\n\n\n\n\n지느러미 분석 결과\n\n평균적으로 보았을때, Gentoo가 보통 가장 긴 지느러미 길이를 가지고 있다.\n최대 지느러미 길이 역시 Gentoo가 가지고 있다.\n가장 짧은 지느러미 길이를 가지고 있는 종은 Adelie이다."
  },
  {
    "objectID": "posts/palmer_penguin_analysis/index.html#각-종별-몸무게-분석",
    "href": "posts/palmer_penguin_analysis/index.html#각-종별-몸무게-분석",
    "title": "Palmer Penguin Analysis",
    "section": "각 종별 몸무게 분석",
    "text": "각 종별 몸무게 분석\n\n# body_mass_g\ng_body_desc = gentoo['body_mass_g'].describe()\na_body_desc = adelie['body_mass_g'].describe()\nc_body_desc = chinstrap['body_mass_g'].describe()\n\n# 평균, 최대값, 최소값 추출\nmean_val = g_body_desc['mean']\nmax_val = g_body_desc['max']\nmin_val = g_body_desc['min']\n\nmean_val_a = a_body_desc['mean']\nmax_val_a = a_body_desc['max']\nmin_val_a = a_body_desc['min']\n\nmean_val_c = c_body_desc['mean']\nmax_val_c = c_body_desc['max']\nmin_val_c = c_body_desc['min']\n\n# gentoo\nprint(f\"Gentoo의 body_mass의 평균: {mean_val}, 최대값: {max_val}, 최소값: {min_val}\")\n\n# adelie\nprint(f\"Adelie의 body_mass의 평균: {mean_val_a}, 최대값: {max_val_a}, 최소값: {min_val_a}\")\n\n# chinstrap\nprint(f\"Chinstrap의 body_mass의 평균: {mean_val_c}, 최대값: {max_val_c}, 최소값: {min_val_c}\")\n\nGentoo의 body_mass의 평균: 5076.016260162602, 최대값: 6300.0, 최소값: 3950.0\nAdelie의 body_mass의 평균: 3700.662251655629, 최대값: 4775.0, 최소값: 2850.0\nChinstrap의 body_mass의 평균: 3733.0882352941176, 최대값: 4800.0, 최소값: 2700.0\n\n\n\n\n\n\nGentoo\nAdelie\nChinstrap\n\n\n\n\n평균 몸무게\n5076.016\n3700.662\n3733.088\n\n\n최대 몸무게\n6300\n4775\n4800\n\n\n최소 몸무게\n3950\n2850\n2700\n\n\n\n\n몸무게 분석 결과\n\n평균,최대,최소 몸무게를 다 비교해보았을때, 가장 무거운 무게를 가진 종은 Gentoo 종이다.\nChinstrap 종이 가장 가벼운 몸무게를 가지고 있는 것을 알 수 있다."
  },
  {
    "objectID": "posts/Pandas.summary/index.html",
    "href": "posts/Pandas.summary/index.html",
    "title": "Pandas 개념정리",
    "section": "",
    "text": "Pandas 개념정리!!"
  },
  {
    "objectID": "posts/Pandas.summary/index.html#판다스-활용하기",
    "href": "posts/Pandas.summary/index.html#판다스-활용하기",
    "title": "Pandas 개념정리",
    "section": "판다스 활용하기",
    "text": "판다스 활용하기\n\n데이터 프레임(Data Frame)이란?\n각 열에 있는 데이터 타입이 달라도 괜찮다!\n\nimport pandas as pd\n\n# 데이터 프레임 생성\ndf = pd.DataFrame({\n    'col-str': ['one', 'two', 'three', 'four','five'],\n    'col-num': [6, 7, 8, 9, 10]\n})\ndf\nprint(df)\n\nprint(df['col-str'].dtype)  # object\nprint(df['col-num'].dtype)  # integer\n\n  col-str  col-num\n0     one        6\n1     two        7\n2   three        8\n3    four        9\n4    five       10\nobject\nint64\n\n\n\n\n시리즈(series)란 무엇일까?\n1차원 구조를 지님.\n그렇기 때문에 하나의 데이터 타입을 가지고 있다!\n\ndata = [10, 20, 30]\ndf_s = pd.Series(data, index=['one', 'two', 'three'])\nprint(df_s)\ndf_s.shape\n\n# 시리즈는 columns을 통해 열 이름을 확인할 수 없음\n# df_s.columns \n\n# name을 통해 시리즈 이름을 확인할 수 있음\ndf_s.name\n\none      10\ntwo      20\nthree    30\ndtype: int64\n\n\n\n데이터 프레임 채우면서 만들기\n\nmy_df = pd.DataFrame({\n    'name': ['issac', 'bomi'],\n    'birthmonth': [5, 4]\n})\nprint(my_df)\n\n    name  birthmonth\n0  issac           5\n1   bomi           4\n\n\n\ndf = pd.DataFrame({\n    'studnet_id': [1,2,3],\n    'gender': ['F', 'M', 'F'],\n    'midterm': [38,42,53]\n}, index = [\"first\", \"second\", \"third\"])\nprint(df)\n\ndf['gender'] # gender 행 전체를 가져옴.\n\n        studnet_id gender  midterm\nfirst            1      F       38\nsecond           2      M       42\nthird            3      F       53\n\n\nfirst     F\nsecond    M\nthird     F\nName: gender, dtype: object\n\n\n\nmy_s = pd.Series(['F', 'M', 'F'],\n                  name = \"gender\", index = [\"first\", \"second\", \"third\"])\nmy_s\npd.DataFrame(my_s)\n\n\n\n\n\n\n\n\ngender\n\n\n\n\nfirst\nF\n\n\nsecond\nM\n\n\nthird\nF\n\n\n\n\n\n\n\n\n\ncsv 파일로 읽어오기\n\nurl = \"https://bit.ly/examscore-csv\"\nmydata = pd.read_csv(url)\nmydata.head(10) # 위에서 10개의 열만 가져옴\n\nmydata['gender'].head()\nmydata[['gender','student_id']].head()\n\n\n\n\n\n\n\n\ngender\nstudent_id\n\n\n\n\n0\nF\n1\n\n\n1\nM\n2\n\n\n2\nF\n3\n\n\n3\nM\n4\n\n\n4\nM\n5\n\n\n\n\n\n\n\n\nimport numpy as np \n# mydata\n# mydata[mydata['gender'] == \"F\", :]  # 에러발생\nmydata.loc[mydata['gender'] == \"F\", :]  #작동\nmydata[mydata['gender'] == \"F\"]   #작동\ncheck_f = np.array(mydata['gender'] == \"F\") # 작동\nmydata.iloc[check_f, :]\n\nmydata[mydata['midterm'] &lt;= 15]\n\n\n\n\n\n\n\n\nstudent_id\ngender\nmidterm\nfinal\n\n\n\n\n19\n20\nM\n9\n33\n\n\n21\n22\nM\n15\n12\n\n\n\n\n\n\n\n\n# 중간고사 점수 45 - 60점 사이 학생은 몇명인가요?\ncheck_score = (mydata['midterm'] &gt;= 45) & (mydata['midterm'] &lt;= 60)\nmydata[check_score].shape[0]\n\n10\n\n\n\n\n\n데이터 프레임 인덱싱\n데이터 프레임 내의 특정 데이터를 효율적으로 필터링 및 조작할 수 있다.\n\niloc[]를 이용한 필터링\n\n# 대괄호 안에 숫자를 써서 인덱스 불가\n# .iloc 함수를 사용하면 가능!\n# mydata[1:4,0]  불가능!\nmydata.iloc[0, 0] # 1행 1열에 있는 숫자 -&gt; 1!\nmydata.iloc[1:4,1:3]\n\n\n\n\n\n\n\n\ngender\nmidterm\n\n\n\n\n1\nM\n42\n\n\n2\nF\n53\n\n\n3\nM\n48\n\n\n\n\n\n\n\n\n# .iloc 함수는 인덱스가 문자여도 잘 작동\nmydata2 = mydata.iloc[:4,:3]\nmydata2.index\nmydata2.index = [\"first\", \"second\", \"third\", \"fourth\"]\nmydata2\nmydata2.iloc[0:2,0]\n\n# .iloc 함수는 : 도 잘 작동함!\nmydata2.iloc[:,0]\n\nfirst     1\nsecond    2\nthird     3\nfourth    4\nName: student_id, dtype: int64\n\n\n리스트 형태로 필터링할 경우 DataFrame으로 변경됨\n\n# .iloc 함수는 결과값의 타입이 변동함.\nmydata2.iloc[0, 1] # 결과 : 값 하나\nmydata2.iloc[0:2, 1] # 결과 : 시리즈\nmydata2.iloc[2, 0:2] # 결과 : 시리즈\nmydata2.iloc[0:3, 0:2]  #결과 :데이터프레임\nresult1 = mydata2.iloc[:,0] # 결과 : 시리즈\nresult2 = mydata2.iloc[:, [0]] # 결과 : 데이터프레임\nresult1[1]                           \nresult2.iloc[1,0]\n\n# DataFrame을 Series로 변경하기 위해서 squeeze()활용!\nmydata2.iloc[:, [0]].squeeze() # 결과: 시리즈\n\nC:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_17616\\3031718094.py:8: FutureWarning:\n\nSeries.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n\n\n\nfirst     1\nsecond    2\nthird     3\nfourth    4\nName: student_id, dtype: int64\n\n\n\n\nloc()를 이용한 필터링\n\n# 라벨을 이용한 인덱싱 loc[] - p20\nmydata.loc[mydata['midterm'] &lt;= 15]\nmydata.loc[mydata['midterm'] &lt;= 15, \"student_id\"]\nmydata.loc[mydata['midterm'] &lt;= 15, [\"student_id\"]]\nmydata.loc[mydata['midterm'] &lt;= 15, [\"student_id\", \"gender\"]]\n\nmydata['midterm'].iloc[0] # 0번째 값이 무엇이 들어있는지 확인\n\n38\n\n\n\n\nisin[] 활용하기\n특정 값이 데이터 프레임 내에 존재하는지 확인하고,\n조건을 만족하는 행을 필터링하는데 사용\n\n# 28,38,52 중 값이 있는지 TRUE,FALSE 값을 반환\nmydata['midterm'].isin([28, 38, 52]) \n# ~를 붙이면 특정값을 제외함(앞줄이랑 반대)\n~mydata['midterm'].isin([28, 38, 52]) \nmydata.loc[mydata['midterm'].isin([28, 38, 52])]\nmydata.loc[~mydata['midterm'].isin([28, 38, 52])]\n\n\n\n\n\n\n\n\nstudent_id\ngender\nmidterm\nfinal\n\n\n\n\n1\n2\nM\n42\n67\n\n\n2\n3\nF\n53\n56\n\n\n3\n4\nM\n48\n54\n\n\n4\n5\nM\n46\n39\n\n\n5\n6\nM\n51\n74\n\n\n6\n7\nM\n48\n36\n\n\n7\n8\nM\n43\n58\n\n\n10\n11\nF\n50\n40\n\n\n11\n12\nF\n29\n44\n\n\n12\n13\nM\n27\n25\n\n\n13\n14\nM\n36\n28\n\n\n14\n15\nM\n29\n47\n\n\n15\n16\nF\n34\n39\n\n\n16\n17\nF\n35\n57\n\n\n17\n18\nF\n46\n86\n\n\n18\n19\nM\n39\n16\n\n\n19\n20\nM\n9\n33\n\n\n20\n21\nM\n76\n79\n\n\n21\n22\nM\n15\n12\n\n\n22\n23\nM\n63\n77\n\n\n24\n25\nM\n49\n58\n\n\n25\n26\nM\n42\n52\n\n\n26\n27\nF\n24\n53\n\n\n28\n29\nF\n65\n78\n\n\n\n\n\n\n\n\n\n\n완전한 표본 체크하기\n\n# 데이터에 빈칸이 뜷려있는 경우\nmydata.iloc[3, 2] = np.nan\nmydata.iloc[10, 3] = np.nan\nmydata.iloc[13, 1] = np.nan\n\nmydata[\"gender\"].isna()\n\nmydata.loc[mydata[\"gender\"].isna()]\nmydata.loc[~mydata[\"gender\"].isna()]\n\nmydata.dropna()\n\n\n\n\n\n\n\n\nstudent_id\ngender\nmidterm\nfinal\n\n\n\n\n0\n1\nF\n38.0\n46.0\n\n\n1\n2\nM\n42.0\n67.0\n\n\n2\n3\nF\n53.0\n56.0\n\n\n4\n5\nM\n46.0\n39.0\n\n\n5\n6\nM\n51.0\n74.0\n\n\n6\n7\nM\n48.0\n36.0\n\n\n7\n8\nM\n43.0\n58.0\n\n\n8\n9\nM\n28.0\n25.0\n\n\n9\n10\nM\n38.0\n59.0\n\n\n11\n12\nF\n29.0\n44.0\n\n\n12\n13\nM\n27.0\n25.0\n\n\n14\n15\nM\n29.0\n47.0\n\n\n15\n16\nF\n34.0\n39.0\n\n\n16\n17\nF\n35.0\n57.0\n\n\n17\n18\nF\n46.0\n86.0\n\n\n18\n19\nM\n39.0\n16.0\n\n\n19\n20\nM\n9.0\n33.0\n\n\n20\n21\nM\n76.0\n79.0\n\n\n21\n22\nM\n15.0\n12.0\n\n\n22\n23\nM\n63.0\n77.0\n\n\n23\n24\nM\n28.0\n55.0\n\n\n24\n25\nM\n49.0\n58.0\n\n\n25\n26\nM\n42.0\n52.0\n\n\n26\n27\nF\n24.0\n53.0\n\n\n27\n28\nF\n52.0\n66.0\n\n\n28\n29\nF\n65.0\n78.0\n\n\n29\n30\nM\n52.0\n65.0\n\n\n\n\n\n\n\n\n# Q. mydata에서 중간고사와 기말고사가 \n# 다 채워진 행들을 가져오세요.\n\ncon1 = ~mydata[\"midterm\"].isna() # 중간고사 채워진 애들\ncon2 = ~mydata[\"final\"].isna() # 기말고사 채워진 애들\n\n\n\n구성원소 추가/삭제/변경\n\n# mydata에 final 열을 추가가\nmydata['total'] = mydata['midterm'] + mydata['final']\nmydata\n\nmydata[\"midterm\"].isna()\n# midterm 열에 빈칸을 50으로 채워줌\nmydata[\"midterm\"].loc[mydata[\"midterm\"].isna()] = 50 \n\nmydata[\"midterm\"].isna().sum() # 빈칸이 몇개 있는지 체크!\nmydata[\"final\"].isna().sum() # 빈칸이 몇개 있는지 체크!\n# final 열에 빈칸을 30으로 채워줌. \nmydata[\"final\"].loc[mydata[\"final\"].isna()] = 30\n\nC:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_17616\\1717743041.py:7: FutureWarning:\n\nChainedAssignmentError: behaviour will change in pandas 3.0!\nYou are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\nA typical example is when you are setting values in a column of a DataFrame, like:\n\ndf[\"col\"][row_indexer] = value\n\nUse `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n\nC:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_17616\\1717743041.py:7: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\nC:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_17616\\1717743041.py:12: FutureWarning:\n\nChainedAssignmentError: behaviour will change in pandas 3.0!\nYou are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\nA typical example is when you are setting values in a column of a DataFrame, like:\n\ndf[\"col\"][row_indexer] = value\n\nUse `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n\nC:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_17616\\1717743041.py:12: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n\n\n\n변경 및 추가\n\n(mydata['total'] / 2).rename('average')\nmydata = pd.concat([mydata, (mydata['total'] /2).rename('average')], axis = 1)\n\n# 열 삭제\ndel mydata[\"gender\"]\n\nmydata.columns\n\nIndex(['student_id', 'midterm', 'final', 'total', 'average'], dtype='object')\n\n\n\n\npd.concat() 함수\n프레임이나 시리즈를 연결하는데 사용\n\n#  에제1 : 두개 데이터 프레임 연결하기(axis=0-행방향)\nimport pandas as pd\ndf1 = pd.DataFrame({\n'A': ['A0', 'A1', 'A2'],\n'B': ['B0', 'B1', 'B2']\n})\ndf2 = pd.DataFrame({\n'A': ['A3', 'A4', 'A5'],\n'B': ['B3', 'B4', 'B5']\n})\nresult = pd.concat([df1, df2])\n\n\n#  에제2 : 열방향으로 연결\ndf3 = pd.DataFrame({\n'C': ['C0', 'C1', 'C2'],\n'D': ['D0', 'D1', 'D2']\n})\n\n# axis = 1 옵션으로 인해 열 방향으로 합쳐졌다.\nresult = pd.concat([df1, df3], axis=1)\n\n\n# 에제3 : ignore_index 옵션 사용\n\n# ignore_index = True 옵션으로 인해 행 번호 중복 출력 x\npd.concat([df1, df2], ignore_index = True)\n\n\n\n\n\n\n\n\nA\nB\n\n\n\n\n0\nA0\nB0\n\n\n1\nA1\nB1\n\n\n2\nA2\nB2\n\n\n3\nA3\nB3\n\n\n4\nA4\nB4\n\n\n5\nA5\nB5\n\n\n\n\n\n\n\n\n# 예제4: join 옵션 사용\ndf4 = pd.DataFrame({\n'A': ['A2', 'A3', 'A4'],\n'B': ['B2', 'B3', 'B4'],\n'C': ['C2', 'C3', 'C4']\n})\n\n# join = 'inner' 는 공통 열만 포함하는 결합\nresult = pd.concat([df1, df4], join='inner')\n\n# join = 'outer'는 모든 열을 포함하는 외부 결합;\n# 하나의 데이터 프레임에만 존재하는 열은 NaN\nresult = pd.concat([df1, df4], join='outer')\n\n\n# 예제 5: keys 옵션 사용\n\n# keys 옵션 사용시 연결된 데이터 프레임의 원본 출처를 \n# 식별하는 멀티인덱스 생성\ndf_wkey = pd.concat([df1, df2], keys=['key1', 'key2'])\ndf_wkey.loc['key2']\n\n\n\n\n\n\n\n\nA\nB\n\n\n\n\n0\nA3\nB3\n\n\n1\nA4\nB4\n\n\n2\nA5\nB5\n\n\n\n\n\n\n\n\n\n\n판다스 데이터 프레임에서 이용가능한 메서드\nhead() - 데이터 프레임의 처음 몇개 행을 반환\n\nimport pandas as pd\nfrom palmerpenguins import load_penguins\ndf = load_penguins()\ndf.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007\n\n\n\n\n\n\n\ntail() - 데이터 프레임의 마지막 몇개의 행을 반환\n\ndf.tail()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n339\nChinstrap\nDream\n55.8\n19.8\n207.0\n4000.0\nmale\n2009\n\n\n340\nChinstrap\nDream\n43.5\n18.1\n202.0\n3400.0\nfemale\n2009\n\n\n341\nChinstrap\nDream\n49.6\n18.2\n193.0\n3775.0\nmale\n2009\n\n\n342\nChinstrap\nDream\n50.8\n19.0\n210.0\n4100.0\nmale\n2009\n\n\n343\nChinstrap\nDream\n50.2\n18.7\n198.0\n3775.0\nfemale\n2009\n\n\n\n\n\n\n\ndescribe() - 데이터 프레임의 요약 통계를 반환\n\ndf.describe()\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nyear\n\n\n\n\ncount\n342.000000\n342.000000\n342.000000\n342.000000\n344.000000\n\n\nmean\n43.921930\n17.151170\n200.915205\n4201.754386\n2008.029070\n\n\nstd\n5.459584\n1.974793\n14.061714\n801.954536\n0.818356\n\n\nmin\n32.100000\n13.100000\n172.000000\n2700.000000\n2007.000000\n\n\n25%\n39.225000\n15.600000\n190.000000\n3550.000000\n2007.000000\n\n\n50%\n44.450000\n17.300000\n197.000000\n4050.000000\n2008.000000\n\n\n75%\n48.500000\n18.700000\n213.000000\n4750.000000\n2009.000000\n\n\nmax\n59.600000\n21.500000\n231.000000\n6300.000000\n2009.000000\n\n\n\n\n\n\n\ninfo() - 데이터 프레임의 정보(컬럼,타입 등)\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 344 entries, 0 to 343\nData columns (total 8 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   species            344 non-null    object \n 1   island             344 non-null    object \n 2   bill_length_mm     342 non-null    float64\n 3   bill_depth_mm      342 non-null    float64\n 4   flipper_length_mm  342 non-null    float64\n 5   body_mass_g        342 non-null    float64\n 6   sex                333 non-null    object \n 7   year               344 non-null    int64  \ndtypes: float64(4), int64(1), object(3)\nmemory usage: 21.6+ KB\n\n\nsort_values() - 특정 열을 기준으로 데이터 프레임 정렬\n\n# 내림차순 정렬: ascending =False\n# 'bill_length_mm' 열을 기준으로 데이터 프레임 정렬 - 오름차순\nsorted_df = df.sort_values(by='bill_length_mm', ascending=False)\nsorted_df.head()\n\n# 'bill_length_mm'를 내림차순으로, 'bill_depth_mm'를 오름차순으로 정렬\nsorted_df = df.sort_values(\nby=['bill_length_mm', 'bill_depth_mm'],\nascending=[False, True]\n)\nsorted_df.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n185\nGentoo\nBiscoe\n59.6\n17.0\n230.0\n6050.0\nmale\n2007\n\n\n293\nChinstrap\nDream\n58.0\n17.8\n181.0\n3700.0\nfemale\n2007\n\n\n253\nGentoo\nBiscoe\n55.9\n17.0\n228.0\n5600.0\nmale\n2009\n\n\n339\nChinstrap\nDream\n55.8\n19.8\n207.0\n4000.0\nmale\n2009\n\n\n267\nGentoo\nBiscoe\n55.1\n16.0\n230.0\n5850.0\nmale\n2009\n\n\n\n\n\n\n\nidmax() & idxmin() - 각 데이터프레임이나 시리즈에서 최대값.최소값을 가지는 첫 인덱스 반환\n\n# 'bill_length_mm' 열에서 최대값을 가지는 행의 인덱스 반환\nmax_idx = df['bill_length_mm'].idxmax()\nmax_idx\n\n# loc 매서드는 해당 인덱스에 위치한 행의 데이터를 출력\ndf.loc[max_idx]\n\nspecies              Gentoo\nisland               Biscoe\nbill_length_mm         59.6\nbill_depth_mm          17.0\nflipper_length_mm     230.0\nbody_mass_g          6050.0\nsex                    male\nyear                   2007\nName: 185, dtype: object\n\n\n\n# 'bill_length_mm' 열에서 최소값을 가지는 행의 인덱스 반환\nmin_idx = df['bill_length_mm'].idxmin()\nmin_idx\n\n# loc 매서드는 해당 인덱스에 위치한 행의 데이터를 출력\ndf.loc[min_idx]\n\nspecies              Adelie\nisland                Dream\nbill_length_mm         32.1\nbill_depth_mm          15.5\nflipper_length_mm     188.0\nbody_mass_g          3050.0\nsex                  female\nyear                   2009\nName: 142, dtype: object\n\n\ngroupby() - 특정 열을 기준으로 데이터 프레임 그룹화\n\n# 'species' 열을 기준으로 그룹화하여 평균 계산\ngrouped_df = df.groupby('species').mean(numeric_only = True)\ngrouped_df\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nyear\n\n\nspecies\n\n\n\n\n\n\n\n\n\nAdelie\n38.791391\n18.346358\n189.953642\n3700.662252\n2008.013158\n\n\nChinstrap\n48.833824\n18.420588\n195.823529\n3733.088235\n2007.970588\n\n\nGentoo\n47.504878\n14.982114\n217.186992\n5076.016260\n2008.080645\n\n\n\n\n\n\n\nmean() - 데이터 프레임의 평균 계산\n\n# 데이터 프레임의 각 열의 평균 계산\nprint(df.mean(numeric_only = True))\n\nbill_length_mm         43.921930\nbill_depth_mm          17.151170\nflipper_length_mm     200.915205\nbody_mass_g          4201.754386\nyear                 2008.029070\ndtype: float64\n\n\n\n# 'species' 열을 기준으로 그룹화하여 평균 계산\ngrouped_df = df.groupby('species').mean(numeric_only = True)\nprint(grouped_df)\n\ndf.groupby('island').mean(numeric_only=True)\n\n           bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g  \\\nspecies                                                                    \nAdelie          38.791391      18.346358         189.953642  3700.662252   \nChinstrap       48.833824      18.420588         195.823529  3733.088235   \nGentoo          47.504878      14.982114         217.186992  5076.016260   \n\n                  year  \nspecies                 \nAdelie     2008.013158  \nChinstrap  2007.970588  \nGentoo     2008.080645  \n\n\n\n\n\n\n\n\n\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nyear\n\n\nisland\n\n\n\n\n\n\n\n\n\nBiscoe\n45.257485\n15.874850\n209.706587\n4716.017964\n2008.095238\n\n\nDream\n44.167742\n18.344355\n193.072581\n3712.903226\n2007.983871\n\n\nTorgersen\n38.950980\n18.429412\n191.196078\n3706.372549\n2007.923077\n\n\n\n\n\n\n\nsum() - 데이터 프레임의 합계 계산\n\n# 데이터 프레임의 각 열의 합계 계산\nprint(df.sum(numeric_only = True))\n\nbill_length_mm         15021.3\nbill_depth_mm           5865.7\nflipper_length_mm      68713.0\nbody_mass_g          1437000.0\nyear                  690762.0\ndtype: float64\n\n\n\n# 최대 부리길이 60인 펭귄은 몇마리?\nsum(df['bill_length_mm'] == 60.0)\n\n0\n\n\n\n\n연습문제\n연습1\n\nmidterm= pd.DataFrame({'id' : [23, 10, 5, 1], 'midterm':[40, 30, 50,20]})\nfinal = pd.DataFrame({'id' : [23, 10, 5, 1], 'final':[45, 25, 50, 17]})\n\npd.merge(midterm, final, on = 'id', how = 'outer')\n\n\n\n\n\n\n\n\nid\nmidterm\nfinal\n\n\n\n\n0\n1\n20\n17\n\n\n1\n5\n50\n50\n\n\n2\n10\n30\n25\n\n\n3\n23\n40\n45\n\n\n\n\n\n\n\n연습2\n\n1 성별, 섬별 부리길이 평균계산\n\n\nbill_length = df.groupby([\"sex\",\"island\"], as_index = False)['bill_length_mm'].mean(numeric_only=True)\n\n\n\n성별, 섬별 부리깊이 평균계산\n\n\n\nbill_depth = df.groupby(['sex','island'], as_index = False)['bill_depth_mm'].mean(numeric_only=True)\n\n\n\n1.2 단계 데이터 프레임 병합해서 성별, 섬별, 부리길이,깊이 데이터 프레임 만들기\n\n\n\nmerged_df = pd.merge(bill_length, bill_depth, on=[\"sex\",\"island\"],how ='outer')\n# 오류 발생??\n# loc는 행 인덱스를 기준으로 접근하는 방법\n# merged_df.loc[\"female\"]\nmerged_df[merged_df['sex'] == 'female']\n\n\n\n\n\n\n\n\nsex\nisland\nbill_length_mm\nbill_depth_mm\n\n\n\n\n0\nfemale\nBiscoe\n43.307500\n15.191250\n\n\n1\nfemale\nDream\n42.296721\n17.601639\n\n\n2\nfemale\nTorgersen\n37.554167\n17.550000\n\n\n\n\n\n\n\nmerge() - 두 데이터 프레임 병합\n\n# 예제 데이터 프레임 생성\ndf1 = pd.DataFrame({'key': ['A', 'B', 'C'], 'value': [1, 2, 3]})\ndf2 = pd.DataFrame({'key': ['A', 'B', 'D'], 'value': [4, 5, 6]})\n\n# 두 데이터 프레임 병합\n# on = 'key' 병합할때 기준이 되는 열 지정\n# how = 'inner'병합 방법지정; inner(교집합), outer(합집합)\nmerged_df = pd.merge(df1, df2, on='key', how='inner') \nprint(merged_df)\n\n# 두 데이터 프레임을 outer join으로 병합\nmerged_df_outer = pd.merge(df1, df2, on='key', how='outer')\nprint(merged_df_outer)\n\n  key  value_x  value_y\n0   A        1        4\n1   B        2        5\n  key  value_x  value_y\n0   A      1.0      4.0\n1   B      2.0      5.0\n2   C      3.0      NaN\n3   D      NaN      6.0\n\n\n\n\n데이터 재구조화 - p69\n\nmelt() 메서드\n데이터를 넓은 형식에서 긴형식으로 변환\n\ndata = {\n    'Date': ['2024-07-01', '2024-07-02', '2024-07-03'],\n    'Temperature': [10, 20, 25],\n    'Humidity': [60, 65, 70]\n}\n\ndf = pd.DataFrame(data)\n\ndf_melted = pd.melt(df,\n    id_vars=['Date'],\n    value_vars=['Temperature', 'Humidity'],\n    var_name='Variable',\n    value_name='Value'\n    )\n\ndf_melted\n\n\n\n\n\n\n\n\nDate\nVariable\nValue\n\n\n\n\n0\n2024-07-01\nTemperature\n10\n\n\n1\n2024-07-02\nTemperature\n20\n\n\n2\n2024-07-03\nTemperature\n25\n\n\n3\n2024-07-01\nHumidity\n60\n\n\n4\n2024-07-02\nHumidity\n65\n\n\n5\n2024-07-03\nHumidity\n70\n\n\n\n\n\n\n\n\n# 또 다른 예제\ndata = {\n    'Country': ['Afghanistan', 'Brazil', 'China'],\n    '2024년': [745, 37737, 212258],\n    '2025년': [2666, 80488, 213766]\n}\n\ndf_wide = pd.DataFrame(data)\ndf_wide\n\ndf_long = pd.melt(df_wide,\n    id_vars = ['Country'],\n    value_vars = ['2024년','2025년'],\n    var_name= 'Year',\n    value_name= 'cases'\n    )\n\n\n\npivot() 메서드\n데이터를 긴형식에서 넓은 형식으로 변환\n\ndf_pivoted = df_melted.pivot(\n    index='Date',\n    columns='Variable',\n    values='Value').reset_index()\ndf_pivoted\n\n\n\n\n\n\n\nVariable\nDate\nHumidity\nTemperature\n\n\n\n\n0\n2024-07-01\n60\n10\n\n\n1\n2024-07-02\n65\n20\n\n\n2\n2024-07-03\n70\n25\n\n\n\n\n\n\n\n\n# 연습데이터\ndata = {\n    'Country': ['Afghanistan', 'Brazil', 'China'],\n    '2024년': [745, 37737, 212258],\n    '2025년': [2666, 80488, 213766]\n}\n\ndf_wide = pd.DataFrame(data)\ndf_wide\n\ndf_long = pd.melt(df_wide,\n    id_vars = ['Country'],\n    value_vars = ['2024년','2025년'],\n    var_name= 'Year',\n    value_name= 'cases'\n    )\n\n# pivot 사용해서 wide 형식으로 바꾸려면?\ndf_wide2 = df_long.pivot(\n    index='Country',\n    columns='Year',\n    values='cases').reset_index()\n\ndf_wide2.shape\n\ndf_wide2.iloc[0,0]\ndf_wide2.columns.name = None  # 불필요한 인덱스 이름제거\ndf_wide2\n\n\n\n\n\n\n\n\nCountry\n2024년\n2025년\n\n\n\n\n0\nAfghanistan\n745\n2666\n\n\n1\nBrazil\n37737\n80488\n\n\n2\nChina\n212258\n213766\n\n\n\n\n\n\n\n깔끔한 데이터 조건\n1. 각 칼럼이 하나의 변수를 의미한다.\n2. 각 행이 하나의 관측치를 나타낸다.\n3. 각 칸에 하나의 값이 들어있다.\n\ndf = pd.DataFrame({\n    'School' : ['A','A', 'B', 'B','C', 'C'],\n    'Gender' : [\"M\", 'F', \"M\", 'F', 'M', 'F'],\n    'City' : ['North', 'South', 'North', 'South', 'North', 'South'],\n    'Midterm' : [ 10, 20, 30, 40, 50, 60],\n    'Final' : [5, 15, 25, 35, 45, 55]\n})\n\ndf\n\n\n\n\n\n\n\n\nSchool\nGender\nCity\nMidterm\nFinal\n\n\n\n\n0\nA\nM\nNorth\n10\n5\n\n\n1\nA\nF\nSouth\n20\n15\n\n\n2\nB\nM\nNorth\n30\n25\n\n\n3\nB\nF\nSouth\n40\n35\n\n\n4\nC\nM\nNorth\n50\n45\n\n\n5\nC\nF\nSouth\n60\n55\n\n\n\n\n\n\n\n\n# 학교별 중간고사 평균\ndf.pivot_table(\n    index='School',\n    values=['Midterm', 'Final'],\n    aggfunc = 'mean').reset_index()\n\n# 학교별 중간고사,기말고사 평균\ndf.pivot_table(\n    index='School',\n    columns='City',\n    values=['Midterm', 'Final'],\n    aggfunc = 'mean').reset_index()\n\n\n\n\n\n\n\n\nSchool\nFinal\nMidterm\n\n\nCity\n\nNorth\nSouth\nNorth\nSouth\n\n\n\n\n0\nA\n5.0\n15.0\n10.0\n20.0\n\n\n1\nB\n25.0\n35.0\n30.0\n40.0\n\n\n2\nC\n45.0\n55.0\n50.0\n60.0\n\n\n\n\n\n\n\n\n# column 옵션에 의미\ndf.pivot_table(\n    index='School',\n    columns='City',\n    values=['Midterm', 'Final'],\n    aggfunc = 'mean').reset_index()\n\n# 인덱스가 여러개\ndf.pivot_table(\n    index=['School', 'Gender'],\n    values='Midterm',\n    aggfunc = 'mean').reset_index()\n\n\n\n\n\n\n\n\nSchool\nGender\nMidterm\n\n\n\n\n0\nA\nF\n20.0\n\n\n1\nA\nM\n10.0\n\n\n2\nB\nF\n40.0\n\n\n3\nB\nM\n30.0\n\n\n4\nC\nF\n60.0\n\n\n5\nC\nM\n50.0\n\n\n\n\n\n\n\n\n# aggfunc의 사용\n# 나만의 함수 \n# 벡터 원소들을 더 한 수의 제곱을 하는 함수 my_f\n\ndef my_f(input):\n    return sum(input)**2\n\ndf.pivot_table(\n    index='School',\n    values='Midterm',\n    aggfunc = my_f).reset_index()\n\n\n\n\n\n\n\n\nSchool\nMidterm\n\n\n\n\n0\nA\n900\n\n\n1\nB\n4900\n\n\n2\nC\n12100\n\n\n\n\n\n\n\n\n\n\n실습 팔머펭귄 데이터 분석 - Pivot table\n\nimport pandas as pd\nfrom palmerpenguins import load_penguins\npenguins = load_penguins()\n\n문제1. 펭귄 종별 평균 부리 길이 구하기\n\npenguins.pivot_table(\n    index='species',\n    values= 'bill_length_mm',\n    aggfunc = 'mean').reset_index()\n\n\n\n\n\n\n\n\nspecies\nbill_length_mm\n\n\n\n\n0\nAdelie\n38.791391\n\n\n1\nChinstrap\n48.833824\n\n\n2\nGentoo\n47.504878\n\n\n\n\n\n\n\n문제2: 섬별 몸무게 중앙값 구하기\n\npenguins.pivot_table(\n    index='island',\n    values= 'body_mass_g',\n    aggfunc = 'median').reset_index()\n\n\n\n\n\n\n\n\nisland\nbody_mass_g\n\n\n\n\n0\nBiscoe\n4775.0\n\n\n1\nDream\n3687.5\n\n\n2\nTorgersen\n3700.0\n\n\n\n\n\n\n\n문제3: 성별에 따른 부리길이와 몸무게 평균 구하기\n\npenguins.pivot_table(\n    index=['sex','species'],\n    values= ['bill_length_mm','body_mass_g'],\n    aggfunc = 'mean').reset_index()\n\n\n\n\n\n\n\n\nsex\nspecies\nbill_length_mm\nbody_mass_g\n\n\n\n\n0\nfemale\nAdelie\n37.257534\n3368.835616\n\n\n1\nfemale\nChinstrap\n46.573529\n3527.205882\n\n\n2\nfemale\nGentoo\n45.563793\n4679.741379\n\n\n3\nmale\nAdelie\n40.390411\n4043.493151\n\n\n4\nmale\nChinstrap\n51.094118\n3938.970588\n\n\n5\nmale\nGentoo\n49.473770\n5484.836066\n\n\n\n\n\n\n\n문제4: 종과 섬에 따른 평균 지느러미 길이 구하기\n\npenguins.pivot_table(\n    index=['species','island'],\n    values= ['flipper_length_mm'],\n    aggfunc = 'mean').reset_index()\n\n\n\n\n\n\n\n\nspecies\nisland\nflipper_length_mm\n\n\n\n\n0\nAdelie\nBiscoe\n188.795455\n\n\n1\nAdelie\nDream\n189.732143\n\n\n2\nAdelie\nTorgersen\n191.196078\n\n\n3\nChinstrap\nDream\n195.823529\n\n\n4\nGentoo\nBiscoe\n217.186992\n\n\n\n\n\n\n\n문제 5: 종과 성별에 따른 부리 깊이 합계 구하기\n\npenguins.pivot_table(\n    index=['species','sex'],\n    values= 'bill_depth_mm',\n    aggfunc = 'sum').reset_index()\n\n\n\n\n\n\n\n\nspecies\nsex\nbill_depth_mm\n\n\n\n\n0\nAdelie\nfemale\n1286.4\n\n\n1\nAdelie\nmale\n1392.3\n\n\n2\nChinstrap\nfemale\n598.0\n\n\n3\nChinstrap\nmale\n654.6\n\n\n4\nGentoo\nfemale\n825.8\n\n\n5\nGentoo\nmale\n958.8\n\n\n\n\n\n\n\n문제6: 종별 몸무게의 변동 범위 구하기\n\ndef my_f(input):\n    return input.max() - input.min()\n\npenguins.pivot_table(\n    index='species',\n    values= 'body_mass_g',\n    aggfunc = my_f).reset_index()\n\n\n\n\n\n\n\n\nspecies\nbody_mass_g\n\n\n\n\n0\nAdelie\n1925.0\n\n\n1\nChinstrap\n2100.0\n\n\n2\nGentoo\n2350.0\n\n\n\n\n\n\n\n\n\n학생 성적 불러오기\n\ndf = df = pd.read_csv('c:\\\\Users\\\\USER\\\\Documents\\\\lsbigdata-gen4\\\\data\\\\dat.csv')\n\ndf.head()\ndf.info()\n\nset(df[\"grade\"])\n\n# 여러 칼럼 선택\ndf.loc[:, ['school', 'sex', 'paid', 'goout']]\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 366 entries, 0 to 365\nData columns (total 11 columns):\n #   Column    Non-Null Count  Dtype  \n---  ------    --------------  -----  \n 0   school    366 non-null    object \n 1   sex       366 non-null    object \n 2   paid      366 non-null    object \n 3   famrel    366 non-null    int64  \n 4   freetime  366 non-null    int64  \n 5   goout     356 non-null    float64\n 6   Dalc      366 non-null    int64  \n 7   Walc      366 non-null    int64  \n 8   health    366 non-null    int64  \n 9   absences  366 non-null    int64  \n 10  grade     366 non-null    int64  \ndtypes: float64(1), int64(7), object(3)\nmemory usage: 31.6+ KB\n\n\n\n\n\n\n\n\n\nschool\nsex\npaid\ngoout\n\n\n\n\n0\nGP\nF\nno\n4.0\n\n\n1\nGP\nF\nno\n3.0\n\n\n2\nGP\nF\nyes\n2.0\n\n\n3\nGP\nF\nyes\n2.0\n\n\n4\nGP\nF\nyes\n2.0\n\n\n...\n...\n...\n...\n...\n\n\n361\nMS\nF\nno\n1.0\n\n\n362\nMS\nM\nyes\n4.0\n\n\n363\nMS\nM\nno\n5.0\n\n\n364\nMS\nM\nno\n1.0\n\n\n365\nMS\nM\nno\n3.0\n\n\n\n\n366 rows × 4 columns\n\n\n\n\n\n칼럼 데이터 타입 변경\n최빈값으로 대체? 기존 데이터 형태의 정수값으로 대체 가능(장점) 전체 변수의 평균값이 변경 될 수 있음(단점)\n평균값으로 대체? 전체 변수의 평균값이 그대로 유지(장점) 데이터 극단값이 존재할 경우 영향을 받을 가능성(단점) 평균값 소수점으로 나올 수 있음(단점)\n\n여러 메서드\nrename() 메서드 특정 칼럼 이름 변경\n\ndf.rename(columns = {'Dalc' : 'dalc', 'Walc' : 'walc'})\n\n\n\n\n\n\n\n\nschool\nsex\npaid\nfamrel\nfreetime\ngoout\ndalc\nwalc\nhealth\nabsences\ngrade\n\n\n\n\n0\nGP\nF\nno\n4\n3\n4.0\n1\n1\n3\n6\n1\n\n\n1\nGP\nF\nno\n5\n3\n3.0\n1\n1\n3\n4\n1\n\n\n2\nGP\nF\nyes\n4\n3\n2.0\n2\n3\n3\n10\n4\n\n\n3\nGP\nF\nyes\n3\n2\n2.0\n1\n1\n5\n2\n9\n\n\n4\nGP\nF\nyes\n4\n3\n2.0\n1\n2\n5\n4\n4\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n361\nMS\nF\nno\n1\n1\n1.0\n1\n1\n5\n0\n0\n\n\n362\nMS\nM\nyes\n5\n5\n4.0\n4\n5\n4\n11\n3\n\n\n363\nMS\nM\nno\n2\n4\n5.0\n3\n4\n2\n3\n10\n\n\n364\nMS\nM\nno\n4\n4\n1.0\n3\n4\n5\n0\n4\n\n\n365\nMS\nM\nno\n3\n2\n3.0\n3\n3\n5\n5\n3\n\n\n\n\n366 rows × 11 columns\n\n\n\nastype() 메서드 데이터 프레임 또는 시리즈의 데이터 타입을 변경하는데 사용\n\n# 최빈값 대체코드\nmode_val = df.loc[:, ['goout']].mode()\ndf['goout'].isna()\n\ndf.loc[df['goout'].isna(), \"goout\"] = 3.0\ndf[\"goout\"] = df.loc[:, ['goout']].astype({'goout' : 'int64'})\ndf\n\n\n\n\n\n\n\n\nschool\nsex\npaid\nfamrel\nfreetime\ngoout\nDalc\nWalc\nhealth\nabsences\ngrade\n\n\n\n\n0\nGP\nF\nno\n4\n3\n4\n1\n1\n3\n6\n1\n\n\n1\nGP\nF\nno\n5\n3\n3\n1\n1\n3\n4\n1\n\n\n2\nGP\nF\nyes\n4\n3\n2\n2\n3\n3\n10\n4\n\n\n3\nGP\nF\nyes\n3\n2\n2\n1\n1\n5\n2\n9\n\n\n4\nGP\nF\nyes\n4\n3\n2\n1\n2\n5\n4\n4\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n361\nMS\nF\nno\n1\n1\n1\n1\n1\n5\n0\n0\n\n\n362\nMS\nM\nyes\n5\n5\n4\n4\n5\n4\n11\n3\n\n\n363\nMS\nM\nno\n2\n4\n5\n3\n4\n2\n3\n10\n\n\n364\nMS\nM\nno\n4\n4\n1\n3\n4\n5\n0\n4\n\n\n365\nMS\nM\nno\n3\n2\n3\n3\n3\n5\n5\n3\n\n\n\n\n366 rows × 11 columns\n\n\n\nassign() 메서드 새로운 칼럼을 생성하거나 특정 칼러 값을 변경 하는데 사용\n\ndef classify_famrel(famrel):\n     if famrel &lt;= 2:\n        return 'Low'\n     elif famrel &lt;= 4:\n         return 'Medium'\n     else:\n         return 'High'\n\n# famrel_quality 칼럼 생성       \ndf = df.assign(famrel_quality=df['famrel'].apply(classify_famrel))\ndf\n\n\n\n\n\n\n\n\nschool\nsex\npaid\nfamrel\nfreetime\ngoout\nDalc\nWalc\nhealth\nabsences\ngrade\nfamrel_quality\n\n\n\n\n0\nGP\nF\nno\n4\n3\n4\n1\n1\n3\n6\n1\nMedium\n\n\n1\nGP\nF\nno\n5\n3\n3\n1\n1\n3\n4\n1\nHigh\n\n\n2\nGP\nF\nyes\n4\n3\n2\n2\n3\n3\n10\n4\nMedium\n\n\n3\nGP\nF\nyes\n3\n2\n2\n1\n1\n5\n2\n9\nMedium\n\n\n4\nGP\nF\nyes\n4\n3\n2\n1\n2\n5\n4\n4\nMedium\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n361\nMS\nF\nno\n1\n1\n1\n1\n1\n5\n0\n0\nLow\n\n\n362\nMS\nM\nyes\n5\n5\n4\n4\n5\n4\n11\n3\nHigh\n\n\n363\nMS\nM\nno\n2\n4\n5\n3\n4\n2\n3\n10\nLow\n\n\n364\nMS\nM\nno\n4\n4\n1\n3\n4\n5\n0\n4\nMedium\n\n\n365\nMS\nM\nno\n3\n2\n3\n3\n3\n5\n5\n3\nMedium\n\n\n\n\n366 rows × 12 columns\n\n\n\nselect_dtypes() 메서드 데이터프레임에서 특정 데이터 타입을 가진 칼럼만 선택하는데 사용되는 메서드\n\ndf.select_dtypes('number')\ndf.select_dtypes('object')\n\n\ndef standardize(x):\n     return (x - np.nanmean(x)/np.std(x))\n\ndf.select_dtypes('number').apply(standardize, axis = 0)\n\n\n\n\n\n\n\n\nfamrel\nfreetime\ngoout\nDalc\nWalc\nhealth\nabsences\ngrade\n\n\n\n\n0\n-0.41557\n-0.242302\n1.156075\n-0.677095\n-0.789321\n0.408977\n5.310415\n-0.639516\n\n\n1\n0.58443\n-0.242302\n0.156075\n-0.677095\n-0.789321\n0.408977\n3.310415\n-0.639516\n\n\n2\n-0.41557\n-0.242302\n-0.843925\n0.322905\n1.210679\n0.408977\n9.310415\n2.360484\n\n\n3\n-1.41557\n-1.242302\n-0.843925\n-0.677095\n-0.789321\n2.408977\n1.310415\n7.360484\n\n\n4\n-0.41557\n-0.242302\n-0.843925\n-0.677095\n0.210679\n2.408977\n3.310415\n2.360484\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n361\n-3.41557\n-2.242302\n-1.843925\n-0.677095\n-0.789321\n2.408977\n-0.689585\n-1.639516\n\n\n362\n0.58443\n1.757698\n1.156075\n2.322905\n3.210679\n1.408977\n10.310415\n1.360484\n\n\n363\n-2.41557\n0.757698\n2.156075\n1.322905\n2.210679\n-0.591023\n2.310415\n8.360484\n\n\n364\n-0.41557\n0.757698\n-1.843925\n1.322905\n2.210679\n2.408977\n-0.689585\n2.360484\n\n\n365\n-1.41557\n-1.242302\n0.156075\n1.322905\n1.210679\n2.408977\n4.310415\n1.360484\n\n\n\n\n366 rows × 8 columns"
  },
  {
    "objectID": "posts/my-first-post/index.html",
    "href": "posts/my-first-post/index.html",
    "title": "나의 첫 블로그 포스트",
    "section": "",
    "text": "넘파이 패키지를 불러옵시다!\n\nimport numpy as np\n\na = np.array([3,2,15])\na\n\narray([ 3,  2, 15])\n\n\n\n\n\nimport pandas as pd"
  },
  {
    "objectID": "posts/my-first-post/index.html#파이썬-데이터-분석",
    "href": "posts/my-first-post/index.html#파이썬-데이터-분석",
    "title": "나의 첫 블로그 포스트",
    "section": "",
    "text": "넘파이 패키지를 불러옵시다!\n\nimport numpy as np\n\na = np.array([3,2,15])\na\n\narray([ 3,  2, 15])\n\n\n\n\n\nimport pandas as pd"
  },
  {
    "objectID": "posts/Numpy.summary/index.html",
    "href": "posts/Numpy.summary/index.html",
    "title": "NumPy 개념정리",
    "section": "",
    "text": "Numpy 개념정리!!"
  },
  {
    "objectID": "posts/Numpy.summary/index.html#넘파이-활용하기배운것-정리",
    "href": "posts/Numpy.summary/index.html#넘파이-활용하기배운것-정리",
    "title": "NumPy 개념정리",
    "section": "넘파이 활용하기(배운것 정리)",
    "text": "넘파이 활용하기(배운것 정리)\n\nNumPy 배열 생성\n\n# 벡터 생성하기 예제\nimport numpy as np\n\na = np.array([1, 2, 3, 4, 5]) # 숫자형 벡터 생\nb = np.array([\"apple\", \"banana\", \"orange\"])\nc = np.array([True, False, True, True]) #\nprint(\"Numeric Vector:\", a)\nprint(\"String Vector:\", b)\nprint(\"Boolean Vector:\", c)\n\nNumeric Vector: [1 2 3 4 5]\nString Vector: ['apple' 'banana' 'orange']\nBoolean Vector: [ True False  True  True]\n\n\n\n빈 배열 선언 후 채우기\n빈 배열 생성하기 - np.empty() or np.zeros()\n\n# 빈 배열 생성\nx = np.empty(3)\nprint(\"빈 벡터 생성하기:\", x)\n\n빈 벡터 생성하기: [0.  0.5 1. ]\n\n\n\n\n배열을 생성하며 채우기\nnp.arange() - 일정한 간격으로 숫자를 생성하여 반환\n\n0부터 10미만까지의 정수 배열 생성\n\n\nimport numpy as np\n\narr1 = np.arange(10)\nprint(\"Array from 0 to 9:\", arr1)\n\nArray from 0 to 9: [0 1 2 3 4 5 6 7 8 9]\n\n\n\n0부터 2미만까지 0.5간격으로 배열 생성\n\n\narr2 = np.arange(0, 2, 0.5)\nprint(\"0부터 1.5가지 0.5 간격으로 발생:\", arr2)\n\n0부터 1.5가지 0.5 간격으로 발생: [0.  0.5 1.  1.5]\n\n\n\n각 요소를 반복 각 요소를 개별적으로 반복 - np.repeat()\n\n\n# 배열 [1, 2, 4]의 각 요소를 각각 1, 2, 3번 반복\nrepeated_each = np.repeat([1, 2, 4], repeats=[1, 2, 3])\nprint(\"Repeated each element in [1, 2, 4] two times:\", repeated_each)\n\nRepeated each element in [1, 2, 4] two times: [1 2 2 4 4 4]\n\n\n\n백터 전체를 반복해서 붙이기 백터 전체를 반복 - np.tile()\n\n\n# 배열 [1, 2, 4]를 2번 반복\nrepeated_whole = np.tile([1, 2, 4], 2)\nprint(\"벡터 전체를 두번 반복:\", repeated_whole)\n\n벡터 전체를 두번 반복: [1 2 4 1 2 4]\n\n\n\n\n\nNumPy 벡터길이 재는 방법\n\nlen() 함수 사용하기\n배열의 첫번째 차원의 길이를 반환\n\nimport numpy as np\n# 1차원 배열\na = np.array([1, 2, 3, 4, 5])\nlen(a)\n\n5\n\n\n\n\nshape 속성 사용하기\nshape속성은 배열의 각 차원의 크기를 튜플 형태로 반환\n\nimport numpy as np\n\n# 1차원 배열\na = np.array([1, 2, 3, 4, 5])\na.shape\n\n(5,)\n\n\n\n\n배열의 전체 요소 수 구하기\nsize 속성은 배열의 전체 요소 수를 구함\n\nimport numpy as np\n\n\na = np.array([1, 2, 3, 4, 5])\na.size\n\n5"
  },
  {
    "objectID": "posts/Numpy.summary/index.html#numpy를-사용하여-벡터-연산하기",
    "href": "posts/Numpy.summary/index.html#numpy를-사용하여-벡터-연산하기",
    "title": "NumPy 개념정리",
    "section": "NumPy를 사용하여 벡터 연산하기",
    "text": "NumPy를 사용하여 벡터 연산하기\n백터간 덧셈, 뺼셈, 곱셈, 나눗셈 등의 연산은 벡터의 각 요소에 동시 수행됨\n\nimport numpy as np\n\n# 벡터 생성\na = np.array([1, 2, 3])\nb = np.array([4, 5, 6])\n\n# 벡터 간 덧셈\nadd_result = a + b\nprint(\"벡터 덧셈:\", add_result)\n\n# 벡터 간 뺄셈\nsub_result = a - b\nprint(\"벡터 뺄셈:\", sub_result)\n\n# 벡터 간 곱셈\nmul_result = a * b\nprint(\"벡터 곱셈:\", mul_result)\n\n# 벡터 간 나눗셈\ndiv_result = a / b\nprint(\"벡터 나눗셈:\", div_result)\n\n# 벡터 간 나머지 연산\nmod_result = a % b\nprint(\"벡터 나머지 연산:\", mod_result)\n\n벡터 덧셈: [5 7 9]\n벡터 뺄셈: [-3 -3 -3]\n벡터 곱셈: [ 4 10 18]\n벡터 나눗셈: [0.25 0.4  0.5 ]\n벡터 나머지 연산: [1 2 3]"
  },
  {
    "objectID": "posts/Numpy.summary/index.html#백터화vectorized-코드",
    "href": "posts/Numpy.summary/index.html#백터화vectorized-코드",
    "title": "NumPy 개념정리",
    "section": "백터화(Vectorized) 코드",
    "text": "백터화(Vectorized) 코드\n반복문을 사용하지 않고 벡터를 한 번에 처리할 수 있게 해준다.\n이를 통해 여러 값을 동시에 처리 할 수 있고, 가독성과 성능을 높인다.\n\nimport numpy as np\n\n# 백터 덧셈셈\na = np.array([1, 2, 4])\nb = np.array([2, 3, 5])\nc = a + b\nprint(\"벡터 덧셈:\", c)\n\n\n# 상수 곱셈\nx = np.array([1, 2, 4, 5])\ny = x * 2\nprint(\"상수 곱셈:\", y)\n\n벡터 덧셈: [3 5 9]\n상수 곱셈: [ 2  4  8 10]"
  },
  {
    "objectID": "posts/Numpy.summary/index.html#numpy의-브로드캐스팅broadcasting",
    "href": "posts/Numpy.summary/index.html#numpy의-브로드캐스팅broadcasting",
    "title": "NumPy 개념정리",
    "section": "NumPy의 브로드캐스팅(Broadcasting)",
    "text": "NumPy의 브로드캐스팅(Broadcasting)\n길이가 다른 배열 간의 연산을 가능하게 해주는 메커니즘\n\n브로드캐스팅의 기본 원리\n두배열이 차원을 비교할 떄, 끝 차원부터 시작하여 앞으로 진행함\n연산이 가능하려면:\n\n차원의 크기가 같거나\n차원 중 하나의 크기가 1인 경우\n\n\n\n브로드캐스팅이 안되는 경우\n배열의 shape을 맞춰 계산 가능함.\n이 경우 shape을 맞춰서 연산이 가능!\n\n\n브로드캐스팅 되는 경우\nEx- 2차원 배열과 1차원 배열의 덧셈\n\nimport numpy as np\n# 2차원 배열 생성\nmatrix = np.array([[ 0.0, 0.0, 0.0],\n[10.0, 10.0, 10.0],\n[20.0, 20.0, 20.0],\n[30.0, 30.0, 30.0]])\n# 1차원 배열 생성\nvector = np.array([1.0, 2.0, 3.0])\nprint(matrix.shape, vector.shape)\n\n# 브로드캐스팅을 이용한 배열 덧셈\nresult = matrix + vector\nprint(\"브로드캐스팅 결과:\\n\", result)\n\n(4, 3) (3,)\n브로드캐스팅 결과:\n [[ 1.  2.  3.]\n [11. 12. 13.]\n [21. 22. 23.]\n [31. 32. 33.]]\n\n\n\n\n벡터 내적 활용하기\ndot product(백터 내적)은 두 벡터의 요소를 곱한 후 합산하는 연산\n\na = np.array([1, 2, 3])\nb = np.array([4, 5, 6])\ndot_product = np.dot(a, b)\nprint(\"벡터 내적:\", dot_product)\n\n벡터 내적: 32\n\n\n\n\nNumPy 벡터 슬라이싱\n벡터 일부 추출 시 [] 사용\n\nimport numpy as np\n# 벡터 슬라이싱 예제, a를 랜덤하게 채움\nnp.random.seed(42)\na = np.random.randint(1, 21, 10)\nprint(a)\n\nprint(a[1]) # 두 번째 값 추출\n\nprint(a[1:4]) # 인덱스 1부터 3까지 추출; 4는 미포함\n\nprint(a[::2]) #첫번째, 세번째, 다섯번째(2씩 커지며 전체범위 지정)\n\n[ 7 20 15 11  8  7 19 11 11  4]\n20\n[20 15 11]\n[ 7 15  8 19 11]\n\n\n\n\n조건을 만족하는 위치 탐색 np.where()\nnp.where()함수를 이용하여 논리값이 TRUE 인 원소의 위치를 반환하는 역활을 함.\n\nimport numpy as np\na = np.array([1, 5, 7, 8, 10]) # 예시 배열\nresult = np.where(a &lt; 7)\nresult\n\n(array([0, 1], dtype=int64),)\n\n\n\n\n벡터 함수 사용하기\n평균, 합계, 중앙값, 표준편차를 계산 할수 있음\n\nimport numpy as np\n\n# 벡터 함수 사용하기 예제\na = np.array([1, 2, 3, 4, 5])\nsum_a = np.sum(a) # 합계 계산\nmean_a = np.mean(a) # 평균 계산\nmedian_a = np.median(a) # 중앙값 계산\nstd_a = np.std(a, ddof=1) # 표준편차 계산\nsum_a, mean_a, median_a, std_a\n\n(15, 3.0, 3.0, 1.5811388300841898)\n\n\n\n\n빈 칸을 나타내는 방법\n\n데이터가 정의 되지 않은 값 np.nan()\n\nimport numpy as np\na = np.array([20, np.nan, 13, 24, 309])\na\n\n\n# nan 무시 옵션\nnp.nanmean(a) # nan 무시 함수\n\n91.5\n\n\n\n\n데이터값이 없음을 나타내는 None\nNone은 아무런 값도 없는 상태를 나타냄. # None + 1 수치연산 불가(Typeerror 반환)\n\n\n\n여러 벡터들을 묶기\nnp.concatenate() 함수 사용\n\nimport numpy as np\nstr_vec = np.array([\"사과\", \"배\", \"수박\", \"참외\"])\nstr_vec\n\nmix_vec = np.array([\"사과\", 12, \"수박\", \"참외\"], dtype=str)\nmix_vec\n\ncombined_vec = np.concatenate((str_vec, mix_vec))\ncombined_vec\n\narray(['사과', '배', '수박', '참외', '사과', '12', '수박', '참외'], dtype='&lt;U2')\n\n\nnp.column_stack()와 np.row_stack()\n\ncol_stacked = np.column_stack((np.arange(1, 5), np.arange(12, 16)))\ncol_stacked  # 벡터들을 세로로 배열\n\n\nrow_stacked = np.row_stack((np.arange(1, 5), np.arange(12, 16)))\nrow_stacked  # 벡터들을 가로로 배열\n\narray([[ 1,  2,  3,  4],\n       [12, 13, 14, 15]])\n\n\n\n길이가 다른 벡터 합치기\nnp.resize() 함수를 사용하면 길이를 강제로 맞춰줌.\n\nimport numpy as np\n\n# 길이가 다른 벡터\nvec1 = np.arange(1, 5)\nvec2 = np.arange(12, 18)\nvec1 = np.resize(vec1, len(vec2))\nvec1\n\narray([1, 2, 3, 4, 1, 2])\n\n\n\n\n\n여러 조건을 처리하기 - numpy.select()\n각 조건에 대한 결과를 리스트로 작성하여 조건에 따라 결과를 반환할 수 있음.\n\nimport numpy as np\n\nx = np.array([1, -2, 3, -4, 0])\nconditions = [x &gt; 0, x == 0, x &lt; 0]\nchoices = [\"양수\", \"0\", \"음수\"]\nresult = np.select(conditions, choices, default=\"기타\") # 기본값을 문자열로 설정\nprint(result)\n\n['양수' '음수' '양수' '음수' '0']\n\n\n\n\n메모리 절약을 위한 데이터 타입 설정(dtype)\nNumpy 배열 생성할 떄, 기본적으로 float64 타입 사용\nBut, float32 or int32 작은 데이터를 사용하면 메모리를 절약 할 수 있음\n\nimport numpy as np\n\na = np.array([1.0, 2.0, 3.0], dtype=np.float64) # 기본 dtype: float64\nb = np.array([1.0, 2.0, 3.0], dtype=np.float32) # float32로 저장\nprint(\"float64 배열 크기:\", a.nbytes, \"bytes\") # 8 bytes * 3 = 24 bytes\n\nfloat64 배열 크기: 24 bytes\n\n\n\n\n행렬이란?\n벡터들을 사용하여 만들 수 있는 객체\n\n행렬 만들기\nnp.zeros() - 빈 행렬 생성, 사이즈만 지정\n\nimport numpy as np\n\n# 2행 2열 빈 행렬 생성\ny = np.zeros((2, 2))\nprint(\"빈 행렬 y:\\n\", y)\n\n빈 행렬 y:\n [[0. 0.]\n [0. 0.]]\n\n\n\n\n채우면서 만들기\n\n# 1부터 4까지의 수로 채운 2행 2열 행렬 생성\ny = np.arange(1, 5).reshape(2, 2)\nprint(\"1부터 4까지의 수로 채운 행렬 y:\\n\", y)\n\n1부터 4까지의 수로 채운 행렬 y:\n [[1 2]\n [3 4]]\n\n\n\n\norder 옵션\n‘C’ : 행 우선 순서\n‘F’ : 열 우선 순서\n\nimport numpy as np\n\n# 가로 방향으로 채우기 (기본값)\ny = np.arange(1, 5).reshape((2, 2), order='C')\nprint(\"가로 방향으로 채운 행렬 y:\\n\", y)\n\n\nimport numpy as np\n\n# 가로 방향으로 채우기\ny = np.arange(1, 5).reshape((2, 2), order='F')\nprint(\"가로 방향으로 채운 행렬 y:\\n\", y)\n\n가로 방향으로 채운 행렬 y:\n [[1 2]\n [3 4]]\n가로 방향으로 채운 행렬 y:\n [[1 3]\n [2 4]]\n\n\n\n\n\n행렬 인덱싱\n\nimport numpy as np\n\n# 1부터 10까지의 수에 2를 곱한 값으로 5행 2열의 행렬 생성\nx = np.arange(1, 11).reshape((5, 2)) * 2\nprint(\"행렬 x:\\n\", x)\n\n# 1행 2열의 원소 접근\nelement = x[0, 1]\nprint(\"1행 2열의 원소:\", element)\n\n# 두번째 열의 모든 원소 반환\nsecond_column = x[:, 1]\nprint(\"두 번째 열의 모든 원소:\", second_column)\n\n# 세번째 행의 모든 원소 반환\nthird_row = x[2, :]\nprint(\"세 번째 행의 모든 원소:\", third_row)\n\n# 두 번째 열에서 두 번째, 세 번째, 다섯 번째 행의 원소 반환\nselected_elements = x[[1, 2, 4], 1]\nprint(\"두번째 열의 2, 3, 5번째 행의 원소: \\n\", selected_elements)\n\n# 두 번째 열의 원소가 15보다 큰 행의 첫 번째 열의 원소 반환\nfiltered_elements = x[x[:, 1] &gt; 15, 0]\nprint(\"두 번째 열의 원소가 15보다 큰 행의 첫 번째 열의 원소:\\n\", filtered_elements)\n\n행렬 x:\n [[ 2  4]\n [ 6  8]\n [10 12]\n [14 16]\n [18 20]]\n1행 2열의 원소: 4\n두 번째 열의 모든 원소: [ 4  8 12 16 20]\n세 번째 행의 모든 원소: [10 12]\n두번째 열의 2, 3, 5번째 행의 원소: \n [ 8 12 20]\n두 번째 열의 원소가 15보다 큰 행의 첫 번째 열의 원소:\n [14 18]\n\n\n\n\n사진은 행렬이다.\n\nimport matplotlib.pyplot as plt\n\n# 난수 생성하여 3x3 크기의 행렬 생성\nnp.random.seed(2024)\nimg1 = np.random.rand(3, 3)\n\n# 행렬을 이미지로 표시\nplt.figure(figsize=(10, 5)) # (가로, 세로) 크기 설정\nplt.imshow(img1, cmap='gray', interpolation='nearest')\nplt.colorbar()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n행렬의 연산\n\n행렬 뒤집기(Transpose)\n주어진 행렬의 행과 열을 뒤집어 반환함.\n\nimport numpy as np\n\n# 5행 2열의 행렬 생성\nx = np.arange(1, 11).reshape((5, 2)) * 2\nprint(\"원래 행렬 x:\\n\", x)\n\n원래 행렬 x:\n [[ 2  4]\n [ 6  8]\n [10 12]\n [14 16]\n [18 20]]\n\n\n\n\n행렬의 곱셈(dot prodcut)\n행렬의 곱셍은 행렬 크기가 맞아야 가능함.\n\n# 2행 3열의 행렬 y 생성\ny = np.arange(1, 7).reshape((2, 3))\nprint(\"행렬 y:\\n\", y)\nx.shape\ny.shape\n\n# 행렬곱 계산\ndot_product = x.dot(y)\nprint(\"행렬곱 x * y:\\n\", dot_product)\n\n# 행렬 곱셈 (matmul 사용)\nmatrix_product = np.matmul(x, y) # 행렬 곱셈 전용\nprint(\"행렬 곱셈 (matmul 사용):\\n\", matrix_product)\n\n행렬 y:\n [[1 2 3]\n [4 5 6]]\n행렬곱 x * y:\n [[ 18  24  30]\n [ 38  52  66]\n [ 58  80 102]\n [ 78 108 138]\n [ 98 136 174]]\n행렬 곱셈 (matmul 사용):\n [[ 18  24  30]\n [ 38  52  66]\n [ 58  80 102]\n [ 78 108 138]\n [ 98 136 174]]\n\n\n\n\n원소별 곱셈\n행렬의 크기가 같은 경우, 각 원소별로 곱셈을 수행 할 수 있음\n\nz = np.arange(10, 14).reshape((2, 2))\n\ny = np.array([[1, 2], [3, 4]])\n\n# 원소별 곱셈 계산\nelementwise_product = y * z\nelementwise_product\n\narray([[10, 22],\n       [36, 52]])\n\n\n\n\n행렬의 역행렬\nnp.linalg.inv() - 함수 사용(행렬의 역행렬 반환) 역행렬이 존재하지 않는 경우 오류 반환\n\n# 2행 2열의 정사각행렬 y 생성\ny = np.array([[1, 2], [3, 4]])\n\n# 행렬 y의 역행렬 계산\ninverse_y = np.linalg.inv(y)\ninverse_y\n\narray([[-2. ,  1. ],\n       [ 1.5, -0.5]])\n\n\n\n\n\nNumPy 배열 기본 제공 함수들\nsum()\naxis = 0(열별 합계), axis = 1(행별 합계)\n\nimport numpy as np\n\na = np.array([[1, 2, 3], [4, 5, 6]])\n\nprint(\"열별 합계:\", a.sum(axis=0))\nprint(\"행별 합계:\", a.sum(axis=1))\n\n열별 합계: [5 7 9]\n행별 합계: [ 6 15]\n\n\nmean()\naxis = 0(열별 평균) axis = 1(행별 평균)\n\nprint(\"열별 평균:\", a.mean(axis=0))\nprint(\"행별 평균:\", a.mean(axis=1))\n\n열별 평균: [2.5 3.5 4.5]\n행별 평균: [2. 5.]\n\n\nmax()\naxis = 0(열별 최대값), axis = 1(행별 최대값)\n\nprint(\"열별 최댓값:\", a.max(axis=0))\nprint(\"행별 최댓값:\", a.max(axis=1))\n\n열별 최댓값: [4 5 6]\n행별 최댓값: [3 6]\n\n\nmin()\naxis = 0(열별 최솟값), axis = 1(행별 최솟값)\n\nprint(\"열별 최솟값:\", a.min(axis=0))\nprint(\"행별 최솟값:\", a.min(axis=1))\n\n열별 최솟값: [1 2 3]\n행별 최솟값: [1 4]\n\n\nstd()\nddof 옵션을 사용하여 자유도 조정 가능\n\n# ddof = 1은 n-1로 나누어준것을 표현함(표본 표준편차)\nprint(\"표본 표준편차 (ddof=1):\", a.std(ddof=1))\n\n표본 표준편차 (ddof=1): 1.8708286933869707\n\n\nvar()\nddof 옵션을 사용하여 자유도 조정 가능\n\nprint(\"표본 분산 (ddof=1):\", a.var(ddof=1))\n\n표본 분산 (ddof=1): 3.5\n\n\ncumsum()\n배열 원소들의 누적 합계를 반환\naxis = 0(열별 누적합계), axis = 1(행별 누적합계)\n\nprint(\"열별 누적 합계:\", a.cumsum(axis=0))\nprint(\"행별 누적 합계:\", a.cumsum(axis=1))\n\n열별 누적 합계: [[1 2 3]\n [5 7 9]]\n행별 누적 합계: [[ 1  3  6]\n [ 4  9 15]]\n\n\ncumprod()\n배열 원소들의 누적 곱을 반환\naxis = 0(열별 누적 곱), axis = 1(행별 누적곱)\n\nprint(\"열별 누적 곱:\", a.cumprod(axis=0))\nprint(\"행별 누적 곱:\", a.cumprod(axis=1))\n\n열별 누적 곱: [[ 1  2  3]\n [ 4 10 18]]\n행별 누적 곱: [[  1   2   6]\n [  4  20 120]]\n\n\nargmax()\n배열 원소들 중 최댓값의 인덱스를 반환\naxis = 0(열별 최댓값), axis = 1(행별 최댓값)\n\nprint(\"최댓값의 인덱스 (열별):\", a.argmax(axis=0))\nprint(\"최댓값의 인덱스 (행별):\", a.argmax(axis=1))\n\n최댓값의 인덱스 (열별): [1 1 1]\n최댓값의 인덱스 (행별): [2 2]\n\n\nargmin()\n배열 원소들 중 최솟값의 인덱스를 반환\naxis = 0(열별 최댓값의 인덱스), axis =1(행별 최댓값의 인덱스)\n\nprint(\"최솟값의 인덱스 (열별):\", a.argmin(axis=0))\nprint(\"최솟값의 인덱스 (행별):\", a.argmin(axis=1))\n\n최솟값의 인덱스 (열별): [0 0 0]\n최솟값의 인덱스 (행별): [0 0]\n\n\nreshape()\n배열 형상을 반환\n\nb = np.array([1, 2, 3, 4, 5, 6])\nprint(\"형상 변경:\\n\", b.reshape((2, 3)))\n\n형상 변경:\n [[1 2 3]\n [4 5 6]]\n\n\ntranspose()\n배열을 전치\n\nc = np.array([[1, 2, 3], [4, 5, 6]])\nprint(\"전치 배열:\\n\", c.transpose())\n\n전치 배열:\n [[1 4]\n [2 5]\n [3 6]]\n\n\nflatten()\n1차원 배열로 전환\n\nprint(\"1차원 배열:\\n\", c.flatten())\n\n1차원 배열:\n [1 2 3 4 5 6]\n\n\nclip()\n배열의 각 원소들을 주어진 최소값과 최대값의 범위로 자르는 역활을 함.\n\nd = np.array([1, 2, 3, 4, 5])\nprint(\"클립된 배열:\", d.clip(2, 4))\n\n클립된 배열: [2 2 3 4 4]\n\n\ntolist()\n배열을 리스트로 변환\n\nprint(\"리스트:\", d.tolist())\n\n리스트: [1, 2, 3, 4, 5]\n\n\nastype()\n배열 원소들의 타입을 변환\n\ne = np.array([1.1, 2.2, 3.3])\nprint(\"정수형 배열:\", e.astype(int))\n\n정수형 배열: [1 2 3]\n\n\ncopy()\n배열의 복사본을 반환\n\nf = d.copy()\nprint(\"복사본 배열:\", f)\n\n복사본 배열: [1 2 3 4 5]\n\n\n\n얕은/깊은 복사의 개념 이해하기\n변수 d와 f가 연결되어 있어 f의 값을 변경하게 되면,\n연결되어있는 d의 값 역시 변화는 것을 알 수 있다.\n\n# 얕은 복사\nimport numpy as np\nd = np.array([1, 2, 3, 4, 5])\nf = d\nf[0] = 10\n\nprint(\"d:\", d)\nprint(\"f:\", f)\n\nd: [10  2  3  4  5]\nf: [10  2  3  4  5]\n\n\nf의 값이 변해도 d값이 변하지 않는 독립적인 변수가 되었음.\n\n# 깊은 복사\nimport numpy as np\nd = np.array([1, 2, 3, 4, 5])\nf = d.copy()\nf[0] = 10\nprint(\"d:\", d)\n\nprint(\"f:\", f)\n\nd: [1 2 3 4 5]\nf: [10  2  3  4  5]\n\n\nsort() 배열을 정렬\n\ng = np.array([3, 1, 2])\ng.sort()\nprint(\"정렬된 배열:\", g)\n\n정렬된 배열: [1 2 3]\n\n\nargsort() 배열의 원소들을 정렬했을때 인덱스를 반환\n\nh = np.array([3, 1, 2])\nprint(\"정렬된 인덱스:\", h.argsort())\n\n정렬된 인덱스: [1 2 0]\n\n\n\n\n\nNumPy 배열에 apply함수 적용\napply_along_axis()\n넘파이 배열에 함수를 적용\n\narray_3d = np.arange(1, 25).reshape(2, 4, 3).transpose(0, 2, 1)\nprint(array_3d)\n\n# 같은 위치에 있는 값들끼리 비교\ndef my_func(x):\n  return np.min(x)\nnp.apply_along_axis(my_func, axis=0, arr=array_3d)\n\n# 같은 깊이의 행별 최소값\nnp.apply_along_axis(my_func, axis=1, arr=array_3d)\n\n# 같은 깊이의 열별 최소값\nnp.apply_along_axis(my_func, axis=2, arr=array_3d)\n\n[[[ 1  4  7 10]\n  [ 2  5  8 11]\n  [ 3  6  9 12]]\n\n [[13 16 19 22]\n  [14 17 20 23]\n  [15 18 21 24]]]\n\n\narray([[ 1,  2,  3],\n       [13, 14, 15]])"
  },
  {
    "objectID": "posts/Pandas-string.summary/index.html",
    "href": "posts/Pandas-string.summary/index.html",
    "title": "Pandas string 개념정리",
    "section": "",
    "text": "Pandas string 개념정리!!\n\n\n\n# 예제 데이터\nimport numpy as np \nimport pandas as pd  \nimport warnings \nwarnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)\n\ndata = {\n    'date': ['2024-01-01 12:34:56', '2024-02-01 23:45:01', '2024-03-01 06:07:08'],\n    'value': [100, 201, 302]\n}\ndf = pd.DataFrame(data)\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 3 entries, 0 to 2\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   date    3 non-null      object\n 1   value   3 non-null      int64 \ndtypes: int64(1), object(1)\nmemory usage: 180.0+ bytes\n\n\n\n\n\n# 문자열을 날짜 형식으로 변환\n# to_datetime() 활용하여 날짜 형식 변환\ndf['date'] = pd.to_datetime(df['date'])\nprint(df.dtypes)\n\ndate     datetime64[ns]\nvalue             int64\ndtype: object\n\n\n\n\n\n\n# 올바른 형식\npd.to_datetime('03-11-2025')\npd.to_datetime('2025-03-11')\npd.to_datetime('2025/03/11')\npd.to_datetime('03/11/2025')\n\n# pd.to_datetime('11/2024/03') 입력형식이 맞지 않음\npd.to_datetime('11-2025-03', format='%d-%Y-%m')\npd.to_datetime('11-25-03', format='%d-%y-%m')\n\nTimestamp('2025-03-11 00:00:00')\n\n\n\n\n\n\ndt_obj = pd.to_datetime('2025년 03월 11일',\n                        format='%Y년 %m월 %d일')\ndt_obj.year\ndt_obj.month\ndt_obj.day\ndt_obj.day_name()\ndt_obj.weekday()\n\n1"
  },
  {
    "objectID": "posts/Pandas-string.summary/index.html#날짜-및-문자형-변수-다루기",
    "href": "posts/Pandas-string.summary/index.html#날짜-및-문자형-변수-다루기",
    "title": "Pandas string 개념정리",
    "section": "",
    "text": "Pandas string 개념정리!!\n\n\n\n# 예제 데이터\nimport numpy as np \nimport pandas as pd  \nimport warnings \nwarnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)\n\ndata = {\n    'date': ['2024-01-01 12:34:56', '2024-02-01 23:45:01', '2024-03-01 06:07:08'],\n    'value': [100, 201, 302]\n}\ndf = pd.DataFrame(data)\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 3 entries, 0 to 2\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   date    3 non-null      object\n 1   value   3 non-null      int64 \ndtypes: int64(1), object(1)\nmemory usage: 180.0+ bytes\n\n\n\n\n\n# 문자열을 날짜 형식으로 변환\n# to_datetime() 활용하여 날짜 형식 변환\ndf['date'] = pd.to_datetime(df['date'])\nprint(df.dtypes)\n\ndate     datetime64[ns]\nvalue             int64\ndtype: object\n\n\n\n\n\n\n# 올바른 형식\npd.to_datetime('03-11-2025')\npd.to_datetime('2025-03-11')\npd.to_datetime('2025/03/11')\npd.to_datetime('03/11/2025')\n\n# pd.to_datetime('11/2024/03') 입력형식이 맞지 않음\npd.to_datetime('11-2025-03', format='%d-%Y-%m')\npd.to_datetime('11-25-03', format='%d-%y-%m')\n\nTimestamp('2025-03-11 00:00:00')\n\n\n\n\n\n\ndt_obj = pd.to_datetime('2025년 03월 11일',\n                        format='%Y년 %m월 %d일')\ndt_obj.year\ndt_obj.month\ndt_obj.day\ndt_obj.day_name()\ndt_obj.weekday()\n\n1"
  },
  {
    "objectID": "posts/Pandas_Question/index.html",
    "href": "posts/Pandas_Question/index.html",
    "title": "Pandas 연습문제제",
    "section": "",
    "text": "Pandas 문제풀이 !!"
  },
  {
    "objectID": "posts/Pandas_Question/index.html#판다스-연습-문제",
    "href": "posts/Pandas_Question/index.html#판다스-연습-문제",
    "title": "Pandas 연습문제제",
    "section": "판다스 연습 문제",
    "text": "판다스 연습 문제\n\n학교 성적데이터\n\nimport pandas as pd \ndf = pd.read_csv('c:\\\\Users\\\\USER\\\\Documents\\\\lsbigdata-gen4\\\\data\\\\grade.csv')\ndf.head()\ndf.info()\n\ndf['student_id'] =df['student_id'].astype('object')\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 10 entries, 0 to 9\nData columns (total 6 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   student_id  10 non-null     int64 \n 1   name        10 non-null     object\n 2   gender      10 non-null     object\n 3   midterm     10 non-null     int64 \n 4   final       10 non-null     int64 \n 5   assignment  10 non-null     int64 \ndtypes: int64(4), object(2)\nmemory usage: 612.0+ bytes\n\n\nQ. df 데이터 프레임의 정보를 출력하고, 각 열의 데이터 타입을 확인하세요.\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 10 entries, 0 to 9\nData columns (total 6 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   student_id  10 non-null     object\n 1   name        10 non-null     object\n 2   gender      10 non-null     object\n 3   midterm     10 non-null     int64 \n 4   final       10 non-null     int64 \n 5   assignment  10 non-null     int64 \ndtypes: int64(3), object(3)\nmemory usage: 612.0+ bytes\n\n\nQ. midterm 점수가 85점 이상인 학생들의 데이터를 필터링하여 출력하세요.\n\ndf[df['midterm'] &gt;= 85]\n\n\n\n\n\n\n\n\nstudent_id\nname\ngender\nmidterm\nfinal\nassignment\n\n\n\n\n0\n1\nAlice\nF\n85\n88\n95\n\n\n2\n3\nCharlie\nM\n92\n94\n87\n\n\n3\n4\nDavid\nM\n88\n90\n85\n\n\n5\n6\nFrank\nM\n95\n97\n98\n\n\n6\n7\nGrace\nF\n89\n91\n84\n\n\n7\n8\nHannah\nF\n90\n92\n90\n\n\n\n\n\n\n\nQ. final 점수를 기준으로 데이터 프레임을 내림차순으로 정렬하고, 정렬된 데이터 프레임의 첫 5행을 출력하세요.\n\nsort_df = df.sort_values(by='final', ascending = False)\nsort_df\n\n\n\n\n\n\n\n\nstudent_id\nname\ngender\nmidterm\nfinal\nassignment\n\n\n\n\n5\n6\nFrank\nM\n95\n97\n98\n\n\n2\n3\nCharlie\nM\n92\n94\n87\n\n\n7\n8\nHannah\nF\n90\n92\n90\n\n\n6\n7\nGrace\nF\n89\n91\n84\n\n\n3\n4\nDavid\nM\n88\n90\n85\n\n\n0\n1\nAlice\nF\n85\n88\n95\n\n\n9\n10\nJack\nM\n84\n86\n88\n\n\n4\n5\nEve\nF\n76\n79\n77\n\n\n8\n9\nIvan\nM\n77\n78\n81\n\n\n1\n2\nBob\nM\n78\n74\n82\n\n\n\n\n\n\n\nQ. gender 열을 기준으로 데이터 프레임을 그룹화하고, 각 그룹별 midterm과 final의 평균을 계산하여 출력하세요.\n\ngender_average = df.groupby('gender')[['midterm','final']].mean()\ngender_average\n\n\n\n\n\n\n\n\nmidterm\nfinal\n\n\ngender\n\n\n\n\n\n\nF\n85.000000\n87.5\n\n\nM\n85.666667\n86.5\n\n\n\n\n\n\n\nQ. student_id 열을 문자열 타입으로 변환하고, 변환된 데이터 프레임의 정보를 출력하세요.\n\ndf['student_id'] = df['student_id'].astype(float)\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 10 entries, 0 to 9\nData columns (total 6 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   student_id  10 non-null     float64\n 1   name        10 non-null     object \n 2   gender      10 non-null     object \n 3   midterm     10 non-null     int64  \n 4   final       10 non-null     int64  \n 5   assignment  10 non-null     int64  \ndtypes: float64(1), int64(3), object(2)\nmemory usage: 612.0+ bytes\n\n\nQ. assignment 점수의 최대값과 최소값을 가지는 행을 각각 출력하세요.\n\n# 최대값 가지는 행\nmax_score = df['assignment'].idxmax()\ndf.loc[max_score]\n\n# 최소값 가지는 행\nmin_score = df['assignment'].idxmin()\ndf.loc[min_score]\n\nstudent_id    5.0\nname          Eve\ngender          F\nmidterm        76\nfinal          79\nassignment     77\nName: 4, dtype: object\n\n\nQ. midterm, final, assignment 점수의 평균을 계산하여 average 열을 추가하고, 첫 5행을 출력하세요.\n\ndf['average'] = df[['midterm','final','assignment']].mean(axis = 1)\ndf.head(5)\n\n\n\n\n\n\n\n\nstudent_id\nname\ngender\nmidterm\nfinal\nassignment\naverage\n\n\n\n\n0\n1.0\nAlice\nF\n85\n88\n95\n89.333333\n\n\n1\n2.0\nBob\nM\n78\n74\n82\n78.000000\n\n\n2\n3.0\nCharlie\nM\n92\n94\n87\n91.000000\n\n\n3\n4.0\nDavid\nM\n88\n90\n85\n87.666667\n\n\n4\n5.0\nEve\nF\n76\n79\n77\n77.333333\n\n\n\n\n\n\n\nQ. 아래의 추가 데이터를 생성하고, 기존 데이터 프레임과 student_id를 기준으로 병합하여 출력하세요. -&gt; merge() !!!\n\n# 추가 데이터 생성\nadditional_data = {\n'student_id': ['1', '3', '5', '7', '9'],\n'club': ['Art', 'Science', 'Math', 'Music', 'Drama']\n}\ndf_additional = pd.DataFrame(additional_data)\n\nprint(df['student_id'].dtype)\nprint(df_additional['student_id'].dtype)\n\ndf['student_id'] = df['student_id'].astype(str)\ndf_additional['student_id'] = df_additional['student_id'].astype(str)\n\n## 데이터 병합 -&gt; merge() !!!\nmerged_df = pd.merge(df, df_additional, on ='student_id',how = 'left')\nmerged_df\n\nfloat64\nobject\n\n\n\n\n\n\n\n\n\nstudent_id\nname\ngender\nmidterm\nfinal\nassignment\naverage\nclub\n\n\n\n\n0\n1.0\nAlice\nF\n85\n88\n95\n89.333333\nNaN\n\n\n1\n2.0\nBob\nM\n78\n74\n82\n78.000000\nNaN\n\n\n2\n3.0\nCharlie\nM\n92\n94\n87\n91.000000\nNaN\n\n\n3\n4.0\nDavid\nM\n88\n90\n85\n87.666667\nNaN\n\n\n4\n5.0\nEve\nF\n76\n79\n77\n77.333333\nNaN\n\n\n5\n6.0\nFrank\nM\n95\n97\n98\n96.666667\nNaN\n\n\n6\n7.0\nGrace\nF\n89\n91\n84\n88.000000\nNaN\n\n\n7\n8.0\nHannah\nF\n90\n92\n90\n90.666667\nNaN\n\n\n8\n9.0\nIvan\nM\n77\n78\n81\n78.666667\nNaN\n\n\n9\n10.0\nJack\nM\n84\n86\n88\n86.000000\nNaN\n\n\n\n\n\n\n\nQ. gender를 인덱스로, student_id를 열로 사용하여 average 점수에 대한 피벗 테이블을 생성하고 출력하세요.\n\ndf_pivot = df.pivot_table(\n    index = 'gender',\n    columns = 'student_id',\n    values = 'average').reset_index()\ndf_pivot\n\n\n\n\n\n\n\nstudent_id\ngender\n1.0\n10.0\n2.0\n3.0\n4.0\n5.0\n6.0\n7.0\n8.0\n9.0\n\n\n\n\n0\nF\n89.333333\nNaN\nNaN\nNaN\nNaN\n77.333333\nNaN\n88.0\n90.666667\nNaN\n\n\n1\nM\nNaN\n86.0\n78.0\n91.0\n87.666667\nNaN\n96.666667\nNaN\nNaN\n78.666667\n\n\n\n\n\n\n\nQ. midterm, final, assignment의 평균을 구하고, average 열을 생성하시오.성별, 성적 유형(assignment, average, final, midterm)별 평균 점수를 계산하시오.\n\ndf['average'] = df[['midterm','final','assignment']].mean(axis=1)\ndf\n\n# melt() 사용하여 데이터 프레임 변경!\ndf_melted = pd.melt(df,\n            id_vars = ['student_id','name','gender'],\n            value_vars = ['assignment','final','average','midterm'],\n            var_name = 'variable',\n            value_name = 'score')\n\n\naverage_score = df_melted.groupby(['gender','variable'])['score'].mean().reset_index()\naverage_score\n\n\n\n\n\n\n\n\ngender\nvariable\nscore\n\n\n\n\n0\nF\nassignment\n86.500000\n\n\n1\nF\naverage\n86.333333\n\n\n2\nF\nfinal\n87.500000\n\n\n3\nF\nmidterm\n85.000000\n\n\n4\nM\nassignment\n86.833333\n\n\n5\nM\naverage\n86.333333\n\n\n6\nM\nfinal\n86.500000\n\n\n7\nM\nmidterm\n85.666667\n\n\n\n\n\n\n\nQ. midterm, final, assignment의 평균을 구하고, average 열을 생성하시오. 또한, 최대 평균 성적을 가진 학생의 이름과 평균 성적을 출력하시오.\n\ndf['average'] = df[['midterm','final','assignment']].mean(axis=1)\n\nmax_idx = df['average'].idxmax()\ndf.loc[max_idx,['name','average']]\n\nname           Frank\naverage    96.666667\nName: 5, dtype: object\n\n\n\n\n공유 자전거 데이터\n\ndf = pd.read_csv('c:\\\\Users\\\\USER\\\\Documents\\\\lsbigdata-gen4\\\\data\\\\bike_data.csv')\n\n# 데이터 속성변환\ndf = df.astype({'datetime': 'datetime64[ns]',\n                'weather': 'int64',\n                'season': 'object',\n                'workingday': 'object',\n                'holiday': 'object',\n                })\n\nQ. 계절(season) == 1일 때, 가장 대여량이 많은 시간대(hour)을 구하시오.\n\n# 계절이 1인 부분만 추출\ndf_sub = df.loc[df.season == 1, ]\n\n# 시간정보 추출\ndf_sub['hour'] = df_sub['datetime'].dt.hour\n\n## 계절별 및 시간대별 대여량 합계 계산\nsummary_data = (df_sub\n                .groupby(['season','hour'])\n                .agg({'count': 'sum'})\n                .reset_index())\n\nsummary_data.loc[summary_data['count'].idxmax(), 'hour'] \ndf['count'].max()\n\nC:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_16656\\1114509147.py:5: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n\n\n970\n\n\nQ. 각 계절(season)별 평균 대여량(count)을 구하시오.\n\ndf.groupby('season')['count'].mean().reset_index()\n\n\n\n\n\n\n\n\nseason\ncount\n\n\n\n\n0\n1\n103.169811\n\n\n1\n2\n218.803922\n\n\n2\n3\n265.500000\n\n\n3\n4\n218.581197\n\n\n\n\n\n\n\nQ. 특정 달(month) 동안의 총 대여량(count)을 구하시오.\n\ndf['month'] = df['datetime'].dt.month\n\ndf.groupby('month')['count'].sum().reset_index()\n\n# 1월의 총대여량 \ndf[df['month'] == 1]['count'].sum()\n\n2567\n\n\nQ. 가장 대여량이 많은 날짜를 구하시오.\n\ndf['date'] = df['datetime'].dt.date\n\ndf.groupby('date')['count'].sum().max()  # 가장 많은 대여량 합계\ndf.groupby('date')['count'].sum().idxmax() # 가장 많은 대여량 날짜\n\ndatetime.date(2012, 5, 11)\n\n\nQ. 시간대(hour)별 평균 대여량(count)을 구하시오.\n\ndf['hour'] = df['datetime'].dt.hour\n\ndf.groupby('hour')['count'].mean()\n\nhour\n0      43.500000\n1      52.714286\n2      32.842105\n3      12.000000\n4       6.687500\n5      17.750000\n6      58.705882\n7     208.937500\n8     483.055556\n9     260.117647\n10    144.130435\n11    182.000000\n12    277.533333\n13    290.600000\n14    266.842105\n15    255.666667\n16    373.052632\n17    519.200000\n18    447.769231\n19    322.103448\n20    210.083333\n21    196.619048\n22    113.560000\n23     77.352941\nName: count, dtype: float64\n\n\nQ. 특정 요일(weekday) 동안의 총 대여량(count)을 구하시오.\n\ndf['weekday'] = df['datetime'].dt.hour\n\ndf.groupby('weekday')['count'].sum()\n\n#월요일 총 대여량 (월요일 = 0)\ndf[df['weekday'] == 0]['count'].sum()\n\n870\n\n\n\n주어진 Bike Sharing 데이터를 사용하여 넓은 형식(wide format)에서 긴 형식(long format)으로 변환하시오. casual과 registered 열을 하나의 열로 변환하고, 각 기록의 대여 유형과 대여수를 포함하는 긴 형식 데이터프레임을 만드시오.\n\n\ndf_melted = pd.melt(df,\n                    id_vars = ['datetime','season'],\n                    value_vars = ['casual','registered'],\n                    var_name = 'user_type',\n                    value_name = 'user_count')\ndf_melted\n\n\n\n\n\n\n\n\ndatetime\nseason\nuser_type\nuser_count\n\n\n\n\n0\n2011-09-05 17:00:00\n3\ncasual\n37\n\n\n1\n2011-05-17 11:00:00\n2\ncasual\n26\n\n\n2\n2011-11-10 09:00:00\n4\ncasual\n23\n\n\n3\n2011-10-13 07:00:00\n4\ncasual\n5\n\n\n4\n2011-10-15 14:00:00\n4\ncasual\n242\n\n\n...\n...\n...\n...\n...\n\n\n865\n2011-04-07 16:00:00\n2\nregistered\n161\n\n\n866\n2011-09-03 22:00:00\n3\nregistered\n96\n\n\n867\n2011-11-12 22:00:00\n4\nregistered\n88\n\n\n868\n2012-04-11 23:00:00\n2\nregistered\n52\n\n\n869\n2012-01-06 09:00:00\n1\nregistered\n237\n\n\n\n\n870 rows × 4 columns\n\n\n\nQ. 이전에 생성한 긴 형식 데이터프레임을 활용하여 각 계절(season)별로 casual과 registered 사용자의 평균 대여 수(count)를 구하시오.\n\ndf_melted.groupby(['season','user_type'])['user_count'].mean().reset_index()\n\n\n\n\n\n\n\n\nseason\nuser_type\nuser_count\n\n\n\n\n0\n1\ncasual\n14.122642\n\n\n1\n1\nregistered\n89.047170\n\n\n2\n2\ncasual\n48.990196\n\n\n3\n2\nregistered\n169.813725\n\n\n4\n3\ncasual\n55.127273\n\n\n5\n3\nregistered\n210.372727\n\n\n6\n4\ncasual\n29.709402\n\n\n7\n4\nregistered\n188.871795\n\n\n\n\n\n\n\n\n\n로그 데이터\n\ndf = pd.read_csv('c:\\\\Users\\\\USER\\\\Documents\\\\lsbigdata-gen4\\\\data\\\\logdata.csv')\n\nQ. 로그 칼럼에서 연도 정보만 추출하시오.\n\ndf['연도정보'] = df['로그'].str.extract(r'(\\d+)')\n\nQ. 로그 칼럼에서 모든 시간 정보를 추출하시오.\n\ndf['시간정보'] = df['로그'].str.extract(r'(\\d{2}:\\d{2}:\\d{2})')\n\nQ. 로그 칼럼에서 한글 정보만 추출하시오.\n\ndf['한글'] = df['로그'].str.extract(r'([가-힣]+)')\n\nQ. 로그 칼럼에서 특수 문자를 제거하시오.\n\ndf['로그'].str.replace(r'[^a-zA-Z0-9가-힣\\s]', '',regex=True)\n\n0         20240718 123456 User 홍길동 Action Login ID12345\n1     20240718 123500 User 김철수 Action Purchase Amoun...\n2       20240718 123610 User 이영희 Action Logout Time 30s\n3         20240718 123722 User 박지성 Action Login ID67890\n4     20240718 123844 User 최강타 Action Purchase Amoun...\n5       20240718 123950 User 장보고 Action Logout Time 25s\n6     20240718 124056 User 홍길동 Action Purchase Amoun...\n7         20240718 124100 User 김철수 Action Login ID23456\n8     20240718 124210 User 이영희 Action Purchase Amoun...\n9       20240718 124322 User 박지성 Action Logout Time 45s\n10        20240718 124444 User 최강타 Action Login ID78901\n11    20240718 124550 User 장보고 Action Purchase Amoun...\n12      20240718 124656 User 홍길동 Action Logout Time 35s\n13    20240718 124700 User 김철수 Action Purchase Amoun...\n14        20240718 124810 User 이영희 Action Login ID56789\n15    20240718 124922 User 박지성 Action Purchase Amoun...\n16      20240718 125044 User 최강타 Action Logout Time 50s\n17        20240718 125150 User 장보고 Action Login ID34567\n18    20240718 125256 User 홍길동 Action Purchase Amoun...\n19      20240718 125300 User 김철수 Action Logout Time 20s\n20    20240718 125410 User 이영희 Action Purchase Amoun...\n21        20240718 125522 User 박지성 Action Login ID12346\n22    20240718 125644 User 최강타 Action Purchase Amoun...\n23      20240718 125750 User 장보고 Action Logout Time 55s\n24        20240718 125856 User 홍길동 Action Login ID67891\n25    20240718 125900 User 김철수 Action Purchase Amoun...\n26      20240718 130010 User 이영희 Action Logout Time 40s\n27    20240718 130122 User 박지성 Action Purchase Amoun...\n28        20240718 130244 User 최강타 Action Login ID78902\n29    20240718 130350 User 장보고 Action Purchase Amoun...\nName: 로그, dtype: object\n\n\nQ. 로그 칼럼에서 유저, Amount 값을 추출한 후 각 유저별 Amount의 평균값을 계산하시오.\n\ndf['User'] = df['로그'].str.extract(r'User:\\s*([가-힣]+)')\ndf['Amount'] = df['로그'].str.extract(r'Amount:\\s*(\\d+)').astype(float)\n\ndf.groupby('User')['Amount'].mean().reset_index()\n\n\n\n\n\n\n\n\nUser\nAmount\n\n\n\n\n0\n김철수\n3666.666667\n\n\n1\n박지성\n5750.000000\n\n\n2\n이영희\n4250.000000\n\n\n3\n장보고\n5750.000000\n\n\n4\n최강타\n3750.000000\n\n\n5\n홍길동\n4250.000000"
  }
]